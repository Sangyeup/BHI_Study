{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sangyeup/BHI_Study/blob/main/BP_assignment_%EC%97%AC%EC%A7%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU-5LJ82B2Uj"
      },
      "source": [
        "# Model training with Backpropagation\n",
        "\n",
        "- 막히는 부분 있으면, https://github.com/WegraLee/deep-learning-from-scratch/tree/master/ch05 참고!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8nM1K9SnBNe",
        "outputId": "1b8eba6a-9924-4832-c99f-db8bdce91ba6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 52.21 MiB | 28.36 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/deep-learning-from-scratch')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHV0AKv3nEF5",
        "outputId": "13235736-21a2-4240-a278-c39e1e893a73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-from-scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZZjqgj7nMip",
        "outputId": "49a2f40e-7038-46e5-c5a8-7e009f88121a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)  # 상위 경로에 있는 functions, gradient 등을 import할 수 있게\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "g6fTaLttnSVu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAl-lspNB2Up"
      },
      "source": [
        "## 1. Define layers as class\n",
        "\n",
        "* All layers have three methods\n",
        "    - `__init__(self, ...)`\n",
        "    - `forward(self, x)`\n",
        "    - `backward(self, dout)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK81Bjn3B2Uq"
      },
      "source": [
        "### 1.1. Activation layers\n",
        "- ReLU\n",
        "- Sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-9Q8WLNB2Ur"
      },
      "source": [
        "<figure>\n",
        "\n",
        "<img src=\"https://i.imgur.com/FrxDrr5.png\" width=\"600\">\n",
        "\n",
        "<figcaption align=\"center\"> - Backpropagation of relu node\n",
        "</figcaption>\n",
        "    \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WN8Mz4-2B2Ur"
      },
      "outputs": [],
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.mask = None  # input에서 어떤 원소가 0 이하인지 저장하는 mask\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.mask = (x<=0)\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSVwjJ72B2Us"
      },
      "source": [
        "<figure>\n",
        "\n",
        "<img src=\"https://i.imgur.com/riURjqG.png\" width=\"500\">\n",
        "\n",
        "<figcaption align=\"center\"> - Backpropagation of sigmoid node\n",
        "</figcaption>\n",
        "    \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CHNgdSrmB2Ut"
      },
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.out = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = 1/(1+np.exp(-x))\n",
        "        self.out = out\n",
        "        return out\n",
        "  \n",
        "    def backward(self, dout):\n",
        "        dx = dout*(1.0-self.out)*self.out\n",
        "        return dx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJunRTu_B2Uu"
      },
      "source": [
        "### 1.2. Affine layer\n",
        "\n",
        "<figure>\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F994510365B98F75122F136\" width=\"600\">\n",
        "\n",
        "<figcaption align=\"center\"> - Backpropagation of affine layer\n",
        "</figcaption>\n",
        "    \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AEiluYX6B2Uu"
      },
      "outputs": [],
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        out = np.dot(x, self.W)+self.b\n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis = 0)\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vaLIOWEB2Uv"
      },
      "source": [
        "### 1.3. Softmax-with-Loss layer\n",
        "\n",
        "<figure>\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FrWMeM%2FbtqQptySbcy%2FOcmx41ncd8SD6e7nPhVAkK%2Fimg.png\" width=\"600\">\n",
        "\n",
        "<figcaption align=\"center\"> - Backpropagation of softmax-with-loss layer\n",
        "</figcaption>\n",
        "    \n",
        "</figure>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Uvz0AG8iB2Uw"
      },
      "outputs": [],
      "source": [
        "from common.functions import softmax, cross_entropy_error  # 지난번에 이미 구현했으므로 import해서 씁시다\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.loss = None\n",
        "        self.y = None  # softmax의 출력 (확률 벡터)\n",
        "        self.t = None  # 정답 label (one-hot vector)\n",
        "    \n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        self.loss = cross_entropy_error(self.y, self.t)\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        # 이 layer의 output이 최종 loss이므로, 상류에서 오는 미분값은 항상 1\n",
        "        \n",
        "        batch_size = self.t.shape[0]  # 구한 dx를 batch_size로 나누어 sample 1개당 오차를 앞 계층으로 전파하는 것 주의!\n",
        "        dx = (self.y-self.t)/batch_size\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p8rx1THB2Ux"
      },
      "source": [
        "## 2. Implement Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f187bOGWB2Ux"
      },
      "outputs": [],
      "source": [
        "from common.gradient import numerical_gradient  # 지난주에 구현했으니 import해서 사용\n",
        "from collections import OrderedDict  # layer들을 순서대로 저장하기 위해 사용\n",
        "\n",
        "class AnyLayerNet:\n",
        "    \"\"\"\n",
        "    원하는 만큼 layer를 추가하여 구현해 보세요.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size,\n",
        "                 weight_init_std=0.01):\n",
        "        # Initialize parameters\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std*np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "        # Create layers\n",
        "        self.layers = OrderedDict()  # 순서를 기억하는 dictionary\n",
        "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
        "        self.layers['Relu1'] = ReLU()\n",
        "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        ### Type your code below ###\n",
        "        # Hint: SoftmaxWithLoss layer는 여기서 call하지 않음. (prediction 시에는 logit 값만 내놓으면 되니 그런 듯)\n",
        "        # self.layers에 담긴 layer들의 forward만 call할 것.\n",
        "        \n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        # x: 입력 데이터, t: 정답 label\n",
        "        \n",
        "        y = self.predict(x)\n",
        "        # Hint: self.predict에서 lastLayer는 call하지 않았으므로, 여기서 따로 call해줄 것.\n",
        "        \n",
        "        return self.lastLayer.forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis = 1)\n",
        "        if t.ndim != 1: t=np.argmax(t, axis=1)\n",
        "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "    \n",
        "    def numerical_gradient(self, x, t):\n",
        "        # 저번주에 구현했으니 그대로 씁시다\n",
        "        \"\"\"다만, Layer를 2층보다 더 추가했다면 아래 code에도 추가해주어야 함!\"\"\"\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "    \n",
        "    def gradient(self, x, t):\n",
        "        self.loss(x, t)\n",
        "\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        for layer in layers:\n",
        "          dout = layer.backward(dout)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = self.layers['Affine1'].dW\n",
        "        grads['b1'] = self.layers['Affine1'].db\n",
        "        grads['W2'] = self.layers['Affine2'].dW\n",
        "        grads['b2'] = self.layers['Affine2'].db\n",
        "\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1siWEOZyB2U0"
      },
      "source": [
        "## 3. Compare numerical gradient & Backpropagation\n",
        "- 배치 하나로 gradient를 구하는데 각각 얼마나 걸리는지 비교해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bfj8w3tgB2U1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2e82ca-db76-4d71-c876-32376ee33376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from dataset.mnist import load_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = load_mnist(normalize=True, flatten=True, one_hot_label=True)\n",
        "\n",
        "X_batch = X_train[:64]\n",
        "y_batch = y_train[:64]\n",
        "\n",
        "network = AnyLayerNet(input_size=784, hidden_size=50, output_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0hG3RY-bB2U2",
        "outputId": "be5fd457-a44f-4040-cb48-414edfbd9573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 5s, sys: 31 s, total: 1min 36s\n",
            "Wall time: 49.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Get gradient with numerical_gradient\n",
        "grad_numerical = network.numerical_gradient(X_batch, y_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TbmPf6CwB2U4",
        "outputId": "601c6d9a-0856-4cfc-e643-51500332a571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.37 ms, sys: 1.19 ms, total: 6.56 ms\n",
            "Wall time: 5.21 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Get gradient with backrpopagation\n",
        "\n",
        "grad_backprop = network.gradient(X_batch, y_batch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkgVJjzqB2U4"
      },
      "source": [
        "## 4. Train Network\n",
        "    - Backpropagation을 통해 모델을 트레이닝하고,\n",
        "    - Epoch별 Train accuracy, Test accuracy를 plotting해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bwFG55JVB2U5",
        "outputId": "f74b37ae-1e8b-4737-b6eb-ccc1efa2d240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1162 0.1224\n",
            "0.9032333333333333 0.9073\n",
            "0.92415 0.925\n",
            "0.9350166666666667 0.935\n",
            "0.9450166666666666 0.9454\n",
            "0.9466666666666667 0.946\n",
            "0.9562666666666667 0.9533\n",
            "0.96115 0.957\n",
            "0.9618166666666667 0.957\n",
            "0.9653666666666667 0.9604\n",
            "0.9668833333333333 0.9621\n",
            "0.9717666666666667 0.9661\n",
            "0.9716166666666667 0.9664\n",
            "0.97465 0.9696\n",
            "0.9754166666666667 0.969\n",
            "0.97425 0.968\n",
            "0.9786666666666667 0.9697\n"
          ]
        }
      ],
      "source": [
        "# 데이터 읽기\n",
        "(X_train, y_train), (X_test, y_test) = load_mnist(normalize=True,\n",
        "                                                  flatten=True,\n",
        "                                                  one_hot_label=True)\n",
        "\n",
        "\n",
        "### Type your code below ###\n",
        "network = AnyLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "iters_num = 10000\n",
        "train_size = X_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "iter_per_epoch = max(train_size/batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = X_train[batch_mask]\n",
        "  t_batch = y_train[batch_mask]\n",
        "\n",
        "  grad = network.gradient(x_batch, t_batch)\n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate*grad[key]\n",
        "  \n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)\n",
        "\n",
        "  if i%iter_per_epoch == 0:\n",
        "    train_acc = network.accuracy(X_train, y_train)\n",
        "    test_acc = network.accuracy(X_test, y_test)\n",
        "    train_acc_list.append(train_acc)\n",
        "    test_acc_list.append(test_acc)\n",
        "    print(train_acc, test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XmB8UTvhB2U5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e7c01338-19ad-4e37-9159-a7ccd13d4fdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcdb3/8ddnJpM9ada2dKELFKSgtFIQZRe5tixlk0VBUZHiAhcV+YkbIC4X4arIQ+SCCnIBQUBls2ApFtErBSpraYGWpW26JV2SNk0yycx8fn+cSZmmaZuWSU46834+HnlkzvmemfPJtHnnO99zzveYuyMiIvkjEnYBIiIysBT8IiJ5RsEvIpJnFPwiInlGwS8ikmcU/CIieUbBLyKSZxT8krPM7EkzW29mRWHXIjKYKPglJ5nZWOAIwIHpA7jfgoHal8iuUvBLrvoMMBf4HXBe90ozG21mfzKzJjNba2a/zGi7wMwWmtlGM1tgZh9Mr3cz2ztju9+Z2Q/Tj482swYz+6aZrQJuM7NqM3skvY/16cejMp5fY2a3mdmKdPsD6fXzzeykjO1iZrbGzCb327skeUnBL7nqM8Bd6a+Pm9kwM4sCjwBLgLHASOAeADM7A7gq/bxKgk8Ja/u4r+FADTAGmEHwe3VbenlPoB34Zcb2dwClwP7AUODn6fX/C5ybsd3xwEp3f6GPdYj0iWmuHsk1ZnY4MAfYw93XmNlrwM0EnwAeSq9P9HjOX4GZ7v6LXl7PgQnuvji9/Dugwd2/a2ZHA7OASnfv2EY9k4A57l5tZnsAy4Fad1/fY7sRwOvASHffYGb3A8+6+7W7/GaI9EI9fslF5wGz3H1Nevn36XWjgSU9Qz9tNPDmLu6vKTP0zazUzG42syVmtgF4CqhKf+IYDazrGfoA7r4C+D/gdDOrAqYRfGIRySodiJKcYmYlwJlAND3mDlAEVAGrgT3NrKCX8F8G7LWNl20jGJrpNhxoyFju+bH5UmBf4EPuvird438BsPR+asysyt2be9nX7cAXCH43n3b35dv+aUV2jXr8kmtOAZLARGBS+ms/4B/ptpXANWZWZmbFZnZY+nm/Ab5hZgdZYG8zG5NuexH4lJlFzWwqcNQOaqggGNdvNrMa4MruBndfCTwK/Cp9EDhmZkdmPPcB4IPAJQRj/iJZp+CXXHMecJu7L3X3Vd1fBAdXPwmcBOwNLCXotZ8F4O73AT8iGBbaSBDANenXvCT9vGbgnHTb9lwPlABrCI4rPNaj/dNAF/Aa0Ah8tbvB3duBPwLjgD/t5M8u0ic6uCsyyJjZFcA+7n7uDjcW2QUa4xcZRNJDQ+cTfCoQ6Rca6hEZJMzsAoKDv4+6+1Nh1yO5S0M9IiJ5Rj1+EZE8M+jH+Ovq6nzs2LFhlyEislv597//vcbd63trG/TBP3bsWObNmxd2GSIiuxUzW7KttqwN9ZjZrWbWaGbzt9FuZnaDmS02s5e7Zz4UEZGBlc0x/t8BU7fTPg2YkP6aAdyUxX2LiEgfZS3406efrdvOJicD/+uBuQSTVu2Rrf2LiEjfDORZPSMJzlHu1pBetxUzm2Fm88xsXlNT04AUJyKSLwbl6Zzufou7T3H3KfX1vR6UFhGRXTSQwb+cYC7ybqPS60REZAANZPA/BHwmfXbPoUBLeopaEREZQFk7j9/M7gaOBurMrIFgDvIYgLv/DzCT4B6iiwlubPG5bO1bRGR30plIsSmeoDWeYGNHgk2dCVo7guXW+LuPj5hQx5SxNTt+wZ2UteB390/uoN2Br2RrfyKy+3J34okU7Z1JOhJJOroyH3d/bdn+7vpgOZFy3J2UO8lU8JpJd1IOKXdSqaAt5Wz5ePNzgmV3x8woiBjR9FdBxIiYURBNf48YkUj3NhGiESiIRDZvE40YUQu26ehKBmHeI8Rb48G6jfEEnYlUn96nsqLo4A5+ERl83J32dBBt7OhiQ0di8+MtvyfY0NHFhvaMdfEuNsWTpNITOVr6Nc1si+Vg3eZHWyxbRrs7dCaDMI/3EnxGiiK6KCFOCZ10EaWJagA+EplPGR2UWCeV0S4qol28Y6N5vuADRMw4Jfk4FgEnglkEzFgSHcPbsX2IkuLIrn9CJAoWAQwzY2VsT1YW7kmMBBM7XiSB0eUREikj4cZyG04jNUSSnYxMLqUrFaHLja50e2Oqgo1eCqlOKlIb6UoFzy8pgKoi8KIhFBSXURvrYr+SRioqnfIYlBekKC9w2mr3o6BiKHWptYxoeZ7iSIqSSJKiSIriaIrYAacQrer1xMf3TMEv0k8ye7VtXUnaOxO0dSZp60wG6zqTtHUmaO8KlhMppyuZIpF0EiknkQx6tYlUsK4rmX7c3da9XSpFVzLowSaSKTqTHvQs0wGeSHUHd4oSOimjgzJrp5AEb/hoIgZHFb3BhIImJsQ6qYp2UhmNQ2kpT+/zeaJmHL7qDoZ2vAU45gApmguHMWvEl3GH41beTG18WRD07oDTVLQns/a4EHeYvvznVHetopBOikrjFHqcpsr38+wB36M4FmX6k9Moa2vY4v3bsNdJrD/+ZopjUYb+cgbW2Zrx5gKTz4PpXw+Wrzpt63+AQ78CU78A8Vb4r5O3bj/qm3DMWbBxFfz0pK3bj/sBHHYqrFkMv/zE1u0n/AwOPhVWvAC3HL1lWxKY9lt4/1R4+ym4/cKtn//Je2Dfg+D1+TDza1u3j3w/KPhFdiyeSG7uwWb2art7upviiS2GCLo/+vvm4YDu5cxhAXrdPpFy2juTtHcleoR5MBzR1pkgtXnWc9/cmy0lTonFKSHOGz6aTmLsZcuZaEsoIEmhJSmKJCmyJDMjx5KMlnAI8zmYBRRGkhSSpNASxCzJreUXQkERH+2YzcGdz1BAkhgJSolTWJzg7kNuo6I4xscW/5AJDVveyTFVXE3b1xZTVhjF7r0HFj4E3begjxZC7QROOOXnwfKfmmHZG4BBxILvVYUcecr7g/b7NsHqlemuvgXfh4/gmNM+ELT/IQHrWyFWArFaiJUydMR+7H/YuPQ/3PmQiKfbSyFWQmXNeCpry4L2zzwE0YLNbRSUQEHRuz/M118DHDz17ldhRdAWK4WvPLdlm6egfGjQXlID588GT0Iq+e73mvFBe8UwOOvOjLZU8H3klKC9chSc8NN311sUojEYMTloHzoRzrwjWBeJBd+jMah/X9A+9vCgvmhB8L53b1NUsSu/An0y6OfjnzJlimuStvzT3plkRUs7K5rbWdXSkQ7ujCBvD4YiNrZ3sTGepK29nYr4KgqTbZQQp8w6KCXOQt+TJT6coaznUwVPUEwX4BhBNs1MHcZCG8doa+JTkVkEwwCk242ZkaN4KzKGcTQwPTUn6NGm26M4j5UcT0vJaD7oC5jeeh8lFqfY4xR5nCJvZ+b7r6ejel/ev/J+psz/4VY/54pz/0ls2D5UvnATRX+7cqt2Ln0dKobD334ET12bEQwFwfdLXoKicvjHT+Hle98NjcIyKCyHs38PkQgseBBWv/ru+sJyKK6EfacF+9mwAlKJd9sKCvvrn1YGiJn9292n9Nqm4JeBlkw5jRs7WNHczvLmDlY2t7Ny/SZSTa+T2LAKb22ipHMdtdbCvNS+zElNZgit3F54DeXWSZnFKbUOij3OA1Wf4R9Dz2GsreYbr5+91b7ePuQq2iZ9ntrWRQz//bF4tAgs8u749Mm/hPd/ApbOhf89Zetiz7gtCMdFs+EPPW6BaxZ8XB9/FCx+Ap64OuhdFpame6alcPQ3g57jypeCbQrLMnq1pTDuiKBnt2kttK2BSEG6R5gO+JLqILhTqWB/ZlvXKNILBb9klXv3GLTTlR5/TiRT6fHpJF2JJPF4B+saV9K4sZ1F8RpWNLczZfkdFLY3BqFOM7W2gb+lJnNd4myqi+EFPrXFflJWwIoDvkjy6G8zJNpJ5cPnEyksS4dnafB9wnEw7kjo3AQLHwlCt7AMYmXB48qRUFoTBCceHOATyQMKftnMuzpYv/Jt1q1YTHvjW7S0tjO7/CQa1rczY/m3GN+1mGAoxIl4isU2hgsjV9KVTHGrX8l+vE0EJ0IKA55L7cO5Xd8B4G+FX2d8ZNUW+3s8eRBfTn2DPYaU8GDH5yihg45YDV0ltVA2lOReH6P0I1+gsjgGCx8Oerhl9cFXcVXQ2xWRnba94NfB3RzTFW9nzfI3aV6xmLbGt+lsaeTByk+yvLmdT638CdMST1ADdJ8ZvNqr+CKTGVlVwutlU4gnatOnw0WwSJQNhcM4fo/hFEQiNDcdx4LEGiIWwSKGWQQvG81VoydSEI3QvPSzvJrcSCQSJRKNUVJVz5QR+/H6+44iEjHoeg1ixRRvq/j9ejmzQkSyTj3+3Uyio5WmhjdZt+JN2hrfJrF+KfeXn8PSlgQnNP2WzyT+SMTe/Tft9ChHFdzJ0OpKphc8zd6RVUSqx1BcP44hI/Zi2IhxVJYVbz43W0Ryg3r8uwt3vG0dLauCoZhNje+QXLeURyrOYMHGEg5pvI+vdv2GPYDuGxkkPMJPiz9MtGYM8REfYi7VRKrHUDJ0PFUj9mbYyLE8XdR92tvhIf1gIjKYKPgHWnwj8eXz08H+Nol1S3mycjr/7hjB2FV/5Ttt11IFVKU3b/dCfl5wAO21B5IYMYV/pGLEavakbNg46kbuRf2Isdwf6z717sMh/VAisjtR8PenZAKaFrKBcuauLWHZy0/y2de/RBGpzT329V7OS6lxLK2porbm/fy15j8pqBlD+dBx1I7amxF7jOD2olh668OA7U6JJCKyQwr+bEp2wWuPEF/yHG1vPUPZuvkUpjq4LXEaP098gpqCGFU151AwchIVe0ygZuRejBpWz6/KCjPG2KeH+iOISO5T8O+qjhZY/jwsn0d7bAhPV5/M3MWNfHXel4h6grd9DK9wNBtqDqR8whHcO3F/Dhw9hKKC08OuXETynIJ/Zz1+JanX/kJk7aLNq/6ePJgvdo2kMBqhacQNjN17fz40YThnja6iOKYLhkRkcFHw90EqmeT/3lrH/y1ey4EvLSLWVsGLyTOYb3vDiMl8YO+x/H58LR8cU62gF5FBT8HfB6/ffxUfWPAbZnTdzMTRF/HhybUcOr6Wr4yppqRQQS8iuxcFfx8k1jeQJMIzV0wLphYQEdmNaSKUPijYtIomq1Poi0hOUPD3QWm8kZaCurDLEBHJCgV/H1R2raG9eGjYZYiIZIXG+HfEnQc5moLag8OuREQkK9Tj34F4MsVV7WeydvTHwy5FRCQrFPw70LiuhTLaGT6kaMcbi4jsBhT8O9C54C+8Wnw+41NLwi5FRCQrFPw70LGuAYAhw/YMuRIRkexQ8O9AsnkFcY8xtH542KWIiGSFgn8Hoq0rWU01Q0oLd7yxiMhuQMG/A0Xtq1kXrdc9aUUkZ+g8/h14tPA/SBVFmRR2ISIiWaLg34H7ug5n0uiqHW8oIrKb0FDPdnhXB2Ub3mRURdiViIhkj4J/OzY2LOTRgkuZEn8m7FJERLJGwb8dzY1LASiuGR1yJSIi2aPg3462tcsAqBiq4BeR3KHg346u9csBqNZVuyKSQxT827NhBU1eydCqyrArERHJmqwGv5lNNbPXzWyxmV3eS/ueZjbHzF4ws5fN7Phs7j/b/ln+ca6Pfp7CAv19FJHckbXz+M0sCtwIHAc0AM+Z2UPuviBjs+8C97r7TWY2EZgJjM1WDdn2bGJvGqs0vi8iuSWbXdlDgMXu/pa7dwL3ACf32MaB7nGTIcCKLO4/64atfZb3lbaGXYaISFZlM/hHAssylhvS6zJdBZxrZg0Evf2Le3shM5thZvPMbF5TU1MWS9wJiTjXtH6HqYnZ4exfRKSfDPTg9SeB37n7KOB44A4z26oGd7/F3ae4+5T6+voBLjEQT5/RYxV7hLJ/EZH+ks3gXw5kDoiPSq/LdD5wL4C7Pw0UA3VZrCFrmlcHd9yKVY8KuRIRkezKZvA/B0wws3FmVgicDTzUY5ulwLEAZrYfQfCHNJazfa3pq3ZL63RwV0RyS9aC390TwEXAX4GFBGfvvGpmV5vZ9PRmlwIXmNlLwN3AZ93ds1VDNnXfcrFq2JiQKxERya6sTsvs7jMJDtpmrrsi4/EC4LBs7rO/vFJ5FNd3JvjvuqFhlyIiklW6MmkbFnfW8I/oIVSWxsIuRUQkq3Qjlm2oWzGHo8piuuWiiOQc9fi34bTVv+DcLUetRERygoK/N+5UJdcSLx0ediUiIlmn4O+Fb1pDIQm8XMEvIrlHwd+LDelz+CNDes44ISKy+1Pw96IlHfwltbpqV0Ryj4K/F++UTeLE+A8pGfWBsEsREck6BX8vlrdHme/jGVpXE3YpIiJZp+DvRenbszgp+i+GVhSFXYqISNYp+HvxvmX38sXYo8SientEJPco2XpRGm9kQyyc+wCIiPQ3BX8vqhJNtBdrcjYRyU0K/p662qnwVhJlunhLRHKTgr+HeHoefqscEXIlIiL9Q8Hfw+roHhzUcRMbx08LuxQRkX6h4O9h1cZO1jKEuprasEsREekXCv4ekotm87WC+xleoRuwiEhuUvD3UL50DudHZzKsqizsUkRE+oWCv4foppU0UkNlsW5OJiK5ScHfQ3F7I80FdbrloojkLAV/DxWdTbQW6qpdEcldCv5M7pSlNtBZMizsSkRE+o2CP4MDk7pu4/m9vhh2KSIi/UbBn2Hdpk46k059VWXYpYiI9BsFf4aWxU/zk4JbGBNrCbsUEZF+o+DP0NnwImcVPEl9ZXHYpYiI9BsFf4bE+uUkPELtUN1kXURyl4I/08YVNFFF/ZDSsCsREek3Cv4MhZtWszZSq1suikhO07wEGTqSzvqY5uEXkdym4M/w/4qvZFR1KUeFXYiISD/q05iGmf3JzE4ws5weA1m1oYPhQ4rCLkNEpF/1Nch/BXwKWGRm15jZvv1YUyjiTW9zQ9fVTPLXwy5FRKRf9Sn43X22u58DfBB4B5htZv8ys8+ZWU7csWT9ikUcGX2FupKwKxER6V99Hroxs1rgs8AXgBeAXxD8IXi8XyobYK1NywAorx8dciUiIv2rTwd3zezPwL7AHcBJ7r4y3fQHM5vXX8UNpPi6BgCqho0JuRIRkf7V1x7/De4+0d3/KyP0AXD3Kd2PzWyqmb1uZovN7PLeXsjMzjSzBWb2qpn9/j3UnlW+YQUbvIShdbrJuojktr4G/0Qzq+peMLNqM/ty5gZmFgVuBKYBE4FPmtnEHttMAL4FHObu+wNffS/FZ9O6RDEvsS8VRTrDVURyW1+D/wJ3b+5ecPf1wAU9tjkEWOzub7l7J3APcHLP1wFuTD8fd2/ctbKz7w8V53Flxfd1y0URyXl9Df6oZSRiundf2GObkcCyjOWG9LpM+wD7mNn/mdlcM5va287MbIaZzTOzeU1NTX0s8b1ZtaGDYZqVU0TyQF+D/zGCA7nHmtmxwN3pdTurAJgAHA18Evh15hBSN3e/xd2nuPuU+voBuP9tKsm1jRcy3f/W//sSEQlZXwe0vwlcCHwpvfw48Jse2ywHMs+FHJVel6kBeMbdu4C3zewNgj8Ez+1M0dmW2tjIXr6UxUUeZhkiIgOiT8Hv7ingpvTXtjwHTDCzcQSBfzbB1b6ZHiDo6d9mZnUEQz9v7WzR2bahcQlVQMEQTdAmIrmvr+fxTwD+i+Bsnc0D4e4+PuNxwswuAv4KRIFb3f1VM7samOfuD6Xb/sPMFgBJ4DJ3X5u1n2YXtTQupQooqdMNWEQk9/V1qOc24Erg58AxwOfo5fiAu88EZvZYd0XGYwe+nv4aNDrWBsekK+r3DLkSEZH+19eDuyXu/gRg7r7E3a8CTui/sgZWU6qcfyUnUjdcPX4RyX197fHH01MyL0oP5ywHyvuvrIH1bOnR/DIxijcqNEObiOS+vvb4LwFKgf8EDgLOBc7rr6IG2qoNHdSVF1GgWy6KSB7YYY8/fbHWWe7+DaCVYHw/p1z4xgwOj+4DfCzsUkRE+t0Ou7jungQOH4BaQjO8cwmlhZqjR0TyQ1/T7gUzewi4D9jUvdLd/9QvVQ2k+EbKaCdRPjzsSkREBkRfg78YWAt8NGOdA7t98MfXNVAERCp18ZaI5Ie+Xrmbc+P63davWsJwoLBap3KKSH7o65W7txH08Lfg7p/PekUDrDFRwr+ShzNq+N5hlyIiMiD6OtTzSMbjYuBUYEX2yxl4b8f25utdX2b2HmPDLkVEZED0dajnj5nLZnY38M9+qWiANa7fCLjm4heRvLGr5zBOAIZms5CwHP7SZTxUtIKK4hPDLkVEZED0dYw/6Ba/axXBHP27vZL21WwsqAi7DBGRAdPXoZ6cTcbKribeLj447DJERAZMnyanMbNTzWxIxnKVmZ3Sf2UNkGSCIalmukqHhV2JiMiA6eusZFe6e0v3grs3E8zPv1tLbVxFlBSpij3CLkVEZMD0Nfh72263n9xmXRx+lZhO17DJYZciIjJg+hr888zsZ2a2V/rrZ8C/+7OwgbAqUcG1ibOJjVLwi0j+6GvwXwx0An8A7gE6gK/0V1EDZU3TairZxPDKorBLEREZMH09q2cTcHk/1zLg6l/6Fc8V3cH6yoawSxERGTB9PavncTOryliuNrO/9l9ZA8M2rqSRauoq1OMXkfzR16GeuvSZPAC4+3py4MrdwrbVrIvU6paLIpJX+pp4KTPbs3vBzMbSy2ydu5uyzkY2xurDLkNEZED19ZTM7wD/NLO/AwYcAczot6oGgjvViTW0Dzk07EpERAZUXw/uPmZmUwjC/gXgAaC9Pwvrd57ip5zLsKEHhV2JiMiA6uskbV8ALgFGAS8ChwJPs+WtGHcr7Qn4dcexXDZi37BLEREZUH0d478EOBhY4u7HAJOB5u0/ZXBrXL2cfW0pe5TrwK6I5Je+pl6Hu3cAmFmRu78G7NZd5a4FM/lr0eXsWbBb//0SEdlpfT2425A+j/8B4HEzWw8s6b+y+l/n+uUAVA/bcwdbiojklr4e3D01/fAqM5sDDAEe67eqBoBvWME6L2dYbdWONxYRySE7PcOmu/+9PwoZaAWbVtFELfsW7faTjIqI7JS8PbJZ0rGa5oK6sMsQERlwedvdvbXkPAoKCvlQ2IWIiAywvO3xz2qfyLqhin0RyT95Gfyp9hbe1/oMY0viYZciIjLg8jL4m5e8zK2xnzDRF4VdiojIgMvL4N/YuBSAktpRIVciIjLwshr8ZjbVzF43s8Vmts07dpnZ6Wbm6YnfBlzHuuCOW0OGjglj9yIiocpa8JtZFLgRmAZMBD5pZhN72a6CYO6fZ7K1752VaF5O3GPUDx0eVgkiIqHJZo//EGCxu7/l7p0EN2U/uZftfgD8hOCG7aGIbFzJKqqpqygOqwQRkdBkM/hHAssylhvS6zYzsw8Co939L9t7ITObYWbzzGxeU1NTFksMPFh9Hj+KXUI0Yll/bRGRwW7ADu6aWQT4GXDpjrZ191vcfYq7T6mvz/6tEV+N17O6enLWX1dEZHeQzeBfDozOWB6VXtetAjgAeNLM3iG4mctDA36A153JTQ8yqXjVgO5WRGSwyGbwPwdMMLNxZlYInA081N3o7i3uXufuY919LDAXmO7u87JYw461r+frHTfy4dQLA7pbEZHBImvB7+4J4CLgr8BC4F53f9XMrjaz6dnaz3vVvi44DGFDRoRciYhIOLI6SZu7zwRm9lh3xTa2PTqb++6r5lVLKAGKqnXxlojkp7y7cnfTmqDHX1GvO2+JSH7Ku+DvbA6ON1cNV/CLSH7Ku+B/uu5MPh6/huHVlWGXIiISirwL/mVtMVYUjqdMt1wUkTyVd8G/79J7OLHs1bDLEBEJTd51e49f+zuGlh4RdhkiIqHJrx5/Is4Q30BnqWblFJH8lVfBn2xZETyoVPCLSP7Kq+DfkL7zVqxq5A62FBHJXfkV/E3BxVultaN3sKWISO7Kq+B/veZYJnXcTPmorW4MJiKSN/Iq+FdvjNNMBcOrysMuRUQkNHkV/MPfuIvzCx6jtrwo7FJEREKTV+fx773qUWpjKd1yUUTyWl71+Ms6G9lYmP1bOYqI7E7yJ/jdqUquJV4yLOxKRERClT/B37aWQhIky3Xxlojkt7wZ429rXo15IZFKXbwlIvktb3r8KwvHsF/8Ntr2nhZ2KSIiocqb4F/d0gEYw4aUhl2KiEio8ib4C1/9A9cW3MzwCp3DLyL5LW/G+EtXPsPR0ZcoryoJuxQRkVDlTY8/tmk1TVZDaWHe/K0TEelV3gR/SXw1LQV1YZchIhK6vAn+yq41tBUNDbsMEZHQ5UfwJ7tY7xW0l+8ZdiUiIqHLi+BPWgEf7fwpr4//bNiliIiELi+Cf01rnGTKGTakOOxSRERClxfBv2n+TO6K/YgxsZawSxERCV1eBH/XqgUcFn2V2urqsEsREQldXgR/snkFm7yI+jqdzikikhdXM0VaV7KaGsaWa4xfZDDq6uqioaGBjo6OsEvZ7RQXFzNq1ChisVifn5MXwV/Uvpp1kVrG65aLIoNSQ0MDFRUVjB07FjP9nvaVu7N27VoaGhoYN25cn5+XF0M9KxjKkpL9wi5DRLaho6OD2tpahf5OMjNqa2t3+pNSXvT4ryj4KvsMq+C0sAsRkW1S6O+aXXnf8qLHv3pDnGGVGt8XEYE8CP62ZS/xkP8nk3xB2KWIyCDV3NzMr371q1167vHHH09zc3OWK+pfWQ1+M5tqZq+b2WIzu7yX9q+b2QIze9nMnjCzMdncf2+aV77J+MgqqirK+3tXIrKb2l7wJxKJ7T535syZVFVV9UdZ/SZrY/xmFgVuBI4DGoDnzOwh9y262i8AU9y9zcy+BFwLnJWtGnrTvqYBgIp6TdAmsjv4/sOvsmDFhqy+5sQRlVx50v7bbL/88st58803mTRpEscddxwnnHAC3/ve96iurua1117jjTfe4JRTTmHZsmV0dHRwySWXMGPGDADGjh3LvHnzaG1tZdq0aRx++OH861//YuTIkTz44IOUlGx586eHH36YH/7wh3R2dlJbW8tdd93FsGHDaG1t5eKLL2bevHmYGVdeeSWnn346jz32GN/+9rdJJpPU1dXxxBNPvDb+OpwAAA2tSURBVOf3I5sHdw8BFrv7WwBmdg9wMrA5+N19Tsb2c4Fzs7j/XnWubyDpRs2wUf29KxHZTV1zzTXMnz+fF198EYAnn3yS559/nvnz528+TfLWW2+lpqaG9vZ2Dj74YE4//XRqa2u3eJ1FixZx99138+tf/5ozzzyTP/7xj5x77pYxd/jhhzN37lzMjN/85jdce+21/PSnP+UHP/gBQ4YM4ZVXXgFg/fr1NDU1ccEFF/DUU08xbtw41q1bl5WfN5vBPxJYlrHcAHxoO9ufDzzaW4OZzQBmAOy553vsqW9cSRNVDK/SUI/I7mB7PfOBdMghh2xxbvwNN9zAn//8ZwCWLVvGokWLtgr+cePGMWnSJAAOOugg3nnnna1et6GhgbPOOouVK1fS2dm5eR+zZ8/mnnvu2bxddXU1Dz/8MEceeeTmbWpqarLys4VycNfMzgWmANf11u7ut7j7FHefUl9f/572tTQymiftYEoKo+/pdUQkv5SVlW1+/OSTTzJ79myefvppXnrpJSZPntzrufNFRUWbH0ej0V6PD1x88cVcdNFFvPLKK9x8882hXK2czeBfDozOWB6VXrcFM/sY8B1gurvHs7j/Xv2x+DRuHXJRf+9GRHZjFRUVbNy4cZvtLS0tVFdXU1paymuvvcbcuXN3eV8tLS2MHDkSgNtvv33z+uOOO44bb7xx8/L69es59NBDeeqpp3j77bcBsjbUk83gfw6YYGbjzKwQOBt4KHMDM5sM3EwQ+o1Z3Pc2rW5p1zn8IrJdtbW1HHbYYRxwwAFcdtllW7VPnTqVRCLBfvvtx+WXX86hhx66y/u66qqrOOOMMzjooIOoy5g48rvf/S7r16/ngAMO4MADD2TOnDnU19dzyy23cNppp3HggQdy1lnZORfG3D0rLwRgZscD1wNR4FZ3/5GZXQ3Mc/eHzGw28H5gZfopS919+vZec8qUKT5v3rxdK6hzE+0/Hseje3yF0y68ctdeQ0T63cKFC9lvP02rsqt6e//M7N/uPqW37bM6ZYO7zwRm9lh3Rcbjj2VzfzuSaF5OCXGKyyoGcrciIoNaTl+5u6FxKQCx6pEhVyIiMnjkdPBvbAqCv7R29A62FBHJHzkd/B1rg6t2q4b2+8wQIiK7jZwO/obYGH6f+Cj19bU73lhEJE/k9Hz884o+xK9T9ZxdVrTjjUVE8kRO9/ib161jaHkhEd1yUUS2471Mywxw/fXX09bWlsWK+ldOB/833vw0V0duDrsMERnk8i34c3eoJ5WkKrmOrsr3NtePiITgthO2Xrf/KXDIBdDZBnedsXX7pE/B5HNg01q49zNbtn3uL9vdXc9pma+77jquu+467r33XuLxOKeeeirf//732bRpE2eeeSYNDQ0kk0m+973vsXr1alasWMExxxxDXV0dc+bM2eK1r776ah5++GHa29v5yEc+ws0334yZsXjxYr74xS/S1NRENBrlvvvuY6+99uInP/kJd955J5FIhGnTpnHNNdfs7Lu3Q7kb/JuaiJIiVT487EpEZJDrOS3zrFmzWLRoEc8++yzuzvTp03nqqadoampixIgR/OUvwR+SlpYWhgwZws9+9jPmzJmzxRQM3S666CKuuCK4jvXTn/40jzzyCCeddBLnnHMOl19+OaeeeiodHR2kUikeffRRHnzwQZ555hlKS0uzNjdPTzkb/JvWLKUMiA7RxVsiu53t9dALS7ffXla7wx7+jsyaNYtZs2YxefJkAFpbW1m0aBFHHHEEl156Kd/85jc58cQTOeKII3b4WnPmzOHaa6+lra2NdevWsf/++3P00UezfPlyTj31VACKi4P5xGbPns3nPvc5SktLgexNw9xTzgb/hsYg+ItrdAMWEdk57s63vvUtLrzwwq3ann/+eWbOnMl3v/tdjj322M29+d50dHTw5S9/mXnz5jF69GiuuuqqUKZh7ilnD+6ujIzghsQplA3fO+xSRGSQ6zkt88c//nFuvfVWWltbAVi+fDmNjY2sWLGC0tJSzj33XC677DKef/75Xp/frTvk6+rqaG1t5f7779+8/ahRo3jggQcAiMfjtLW1cdxxx3HbbbdtPlCsoZ6d9FZkT36WOJM5QzXGLyLblzkt87Rp07juuutYuHAhH/7whwEoLy/nzjvvZPHixVx22WVEIhFisRg33XQTADNmzGDq1KmMGDFii4O7VVVVXHDBBRxwwAEMHz6cgw8+eHPbHXfcwYUXXsgVV1xBLBbjvvvuY+rUqbz44otMmTKFwsJCjj/+eH784x9n/efN6rTM/WFXp2X++xtN3Dl3CTecPVl33xIZ5DQt83sT6rTMg8lR+9Rz1D46lVNEpKecHeMXEZHeKfhFZFAY7MPOg9WuvG8KfhEJXXFxMWvXrlX47yR3Z+3atZuvA+irnB3jF5Hdx6hRo2hoaKCpqSnsUnY7xcXFjBq1c9crKfhFJHSxWIxx48aFXUbe0FCPiEieUfCLiOQZBb+ISJ4Z9FfumlkTsGQXn14HrMliOdmiunbOYK0LBm9tqmvn5GJdY9y916tYB33wvxdmNm9blyyHSXXtnMFaFwze2lTXzsm3ujTUIyKSZxT8IiJ5JteD/5awC9gG1bVzBmtdMHhrU107J6/qyukxfhER2Vqu9/hFRKQHBb+ISJ7J2eA3s6lm9rqZLTazy8OuB8DMRpvZHDNbYGavmtklYdeUycyiZvaCmT0Sdi3dzKzKzO43s9fMbKGZfTjsmgDM7Gvpf8P5Zna3me3c9IjZq+NWM2s0s/kZ62rM7HEzW5T+Xj1I6rou/e/4spn92cyqBkNdGW2XmpmbWd1gqcvMLk6/Z6+a2bXZ2l9OBr+ZRYEbgWnAROCTZjYx3KoASACXuvtE4FDgK4Okrm6XAAvDLqKHXwCPufv7gAMZBPWZ2UjgP4Ep7n4AEAXODqmc3wFTe6y7HHjC3ScAT6SXB9rv2Lqux4ED3P0DwBvAtwa6KHqvCzMbDfwHsHSgC0r7HT3qMrNjgJOBA919f+C/s7WznAx+4BBgsbu/5e6dwD0Eb2Co3H2luz+ffryRIMRGhltVwMxGAScAvwm7lm5mNgQ4EvgtgLt3untzuFVtVgCUmFkBUAqsCKMId38KWNdj9cnA7enHtwOnDGhR9F6Xu89y90R6cS6wc3MJ91NdaT8H/h8Qytku26jrS8A17h5Pb9OYrf3lavCPBJZlLDcwSAK2m5mNBSYDz4RbyWbXE/zHT4VdSIZxQBNwW3oI6jdmVhZ2Ue6+nKD3tRRYCbS4+6xwq9rCMHdfmX68ChgWZjHb8Hng0bCLADCzk4Hl7v5S2LX0sA9whJk9Y2Z/N7ODs/XCuRr8g5qZlQN/BL7q7hsGQT0nAo3u/u+wa+mhAPggcJO7TwY2Ec6wxRbSY+YnE/xhGgGUmdm54VbVOw/O1x5U52yb2XcIhj3vGgS1lALfBq4Iu5ZeFAA1BMPClwH3mpll44VzNfiXA6Mzlkel14XOzGIEoX+Xu/8p7HrSDgOmm9k7BMNiHzWzO8MtCQg+qTW4e/enovsJ/hCE7WPA2+7e5O5dwJ+Aj4RcU6bVZrYHQPp71oYI3isz+yxwInCOD46LiPYi+AP+Uvr//yjgeTMbHmpVgQbgTx54luDTeFYOPOdq8D8HTDCzcWZWSHDg7aGQayL91/q3wEJ3/1nY9XRz92+5+yh3H0vwXv3N3UPvwbr7KmCZme2bXnUssCDEkrotBQ41s9L0v+mxDIKDzhkeAs5LPz4PeDDEWjYzs6kEw4nT3b0t7HoA3P0Vdx/q7mPT//8bgA+m/++F7QHgGAAz2wcoJEsziOZk8KcPIF0E/JXgF/Jed3813KqAoGf9aYIe9Yvpr+PDLmqQuxi4y8xeBiYBPw65HtKfQO4HngdeIfg9CuWSfzO7G3ga2NfMGszsfOAa4DgzW0Tw6eSaQVLXL4EK4PH0//3/GSR1hW4bdd0KjE+f4nkPcF62PiVpygYRkTyTkz1+ERHZNgW/iEieUfCLiOQZBb+ISJ5R8IuI5BkFv0iWmdnRg2mGU5GeFPwiInlGwS95y8zONbNn0xcT3Zy+H0Grmf08Pf/5E2ZWn952kpnNzZhLvjq9fm8zm21mL5nZ82a2V/rlyzPuI3BX9xwrZnaNBfdjeNnMsjbNrsjOUPBLXjKz/YCzgMPcfRKQBM4ByoB56fnP/w5cmX7K/wLfTM8l/0rG+ruAG939QIL5erpnxZwMfJXgfhDjgcPMrBY4Fdg//To/7N+fUqR3Cn7JV8cCBwHPmdmL6eXxBBNh/SG9zZ3A4en7AlS5+9/T628HjjSzCmCku/8ZwN07MuagedbdG9w9BbwIjAVagA7gt2Z2GjAo5quR/KPgl3xlwO3uPin9ta+7X9XLdrs6p0k843ESKEjPIXUIwTw/JwKP7eJri7wnCn7JV08AnzCzobD5PrVjCH4nPpHe5lPAP929BVhvZkek138a+Hv6LmoNZnZK+jWK0vO79yp9H4Yh7j4T+BrBrSRFBlxB2AWIhMHdF5jZd4FZZhYBuoCvENzs5ZB0WyPBcQAIpjf+n3SwvwV8Lr3+08DNZnZ1+jXO2M5uK4AHLbgxuwFfz/KPJdInmp1TJIOZtbp7edh1iPQnDfWIiOQZ9fhFRPKMevwiInlGwS8ikmcU/CIieUbBLyKSZxT8IiJ55v8DARa5+n0HVCMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.plot(train_acc_list, label = 'train acc')\n",
        "plt.plot(test_acc_list, label = 'test acc', linestyle = '--')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "BP_assignment_여진.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
