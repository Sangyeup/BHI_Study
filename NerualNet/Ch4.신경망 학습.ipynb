{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aadf66",
   "metadata": {},
   "source": [
    "# Ch4. 신경망 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "485f4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00b75f",
   "metadata": {},
   "source": [
    "## 4.2. 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89f1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSE, Sum of Squares for Error\n",
    "\n",
    "def sum_squares_error(y, t):\n",
    "    return 0.5*np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3250988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "# SSE 사용\n",
    "\n",
    "# MNSIT 정답이 2\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 2로 추정\n",
    "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y1), np.array(t)))\n",
    "\n",
    "# 7로 추정\n",
    "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y2), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c749f0",
   "metadata": {},
   "source": [
    "정답에 가깝게 추정할수록 작은 SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bbff21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEE, Cross Entropy Error\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ed174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "# CEE 사용\n",
    "\n",
    "# MNSIT 정답이 2\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 2로 추정\n",
    "y1 = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y1), np.array(t)))\n",
    "\n",
    "# 7로 추정\n",
    "y2 = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y2), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70abf7",
   "metadata": {},
   "source": [
    "정답에 가깝게 추정할수록 작은 CEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c198b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 학습\n",
    "\n",
    "import sys, os\n",
    "# sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)    # image data (60000개, 28*28=784 length)\n",
    "print(t_train.shape)    # 정답 label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b579822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30422 45090  8867 10476    31 56570  6411 42600 45572 28812]\n"
     ]
    }
   ],
   "source": [
    "# 무작위로 10개 추출\n",
    "# np.random.choice()\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "\n",
    "# 0 ~ 60000 사이에서 무작위로 10 개 추출 -> for index of mini-batch\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "print(batch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a889d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치용 교차 엔트로피 오차\n",
    "# 묶음으로 데이터 입력 시 & 데이터 하나 입력 시 모두 사용 가능하게\n",
    "# 정답 레이블 t -> 원핫인코딩 되어있는 경우\n",
    "\n",
    "def cross_entropy_error(y,t):\n",
    "    # 1차원 데이터 -> 연산 가능한 shape로\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69534310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 레이블 t -> 원핫인코딩x, 숫자 레이블\n",
    "\n",
    "def cross_entropy_error(y,t):\n",
    "    # 1차원 데이터\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    # 정답에 해당하는 값만을 표현\n",
    "    # np.arange(batch_size) : 0 ~ batch_size-1 베열\n",
    "    \n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20946f35",
   "metadata": {},
   "source": [
    "## 4.3. 수치 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9dd1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나쁜 미분 구현\n",
    "\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x+h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a5dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반올림 오차 해결\n",
    "# 전방 차분 -> 중심 차분\n",
    "\n",
    "def numerical_diff(f,x):\n",
    "    h = 1e-4        # 반올림 오차 일어나지 않을 정도로만\n",
    "    return (f(x+h) - f(x-h)) / 2*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64c010e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치 미분 예시\n",
    "# y = 0.01x^2 + 0.1x\n",
    "\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff22a539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAidElEQVR4nO3deXyU1b3H8c8hC5CwZmMPEPZFIBBIUErd8CqlolYtWKQqi1qt0l71emuvtbX31tblurVWFBQkLG644Iq7VAgECGvYIQkQsgCBhEBCknP/mKEX0wQSyDPPzOT7fr3yysw8z+T8ODP58uSZ85xjrLWIiEjwaeJ2ASIi4gwFvIhIkFLAi4gEKQW8iEiQUsCLiASpULcLOF1MTIzt1q2b22WIiASM1atXF1prY2va5lcB361bN9LT090uQ0QkYBhjsmrbplM0IiJBSgEvIhKkFPAiIkHK0YA3xrQxxrxpjNlijMk0xox0sj0REfl/Tn/I+gzwsbX2emNMOBDhcHsiIuLlWMAbY1oBo4FbAKy15UC5U+2JiMj3OXmKJgEoAF4xxqw1xrxsjIl0sD0RETmNkwEfCgwFXrDWJgLHgAer72SMmW6MSTfGpBcUFDhYjoiI/1mddYiXvtnlyM92MuD3AnuttWne+2/iCfzvsdbOtNYmWWuTYmNrvBhLRCQoZeYe5dZXVpGalsWxsooG//mOBby19gCQY4zp433oMmCzU+2JiASSPYXHuHnWSiLCQ3ltSjKRTRv+I1GnR9H8Ekj1jqDZBdzqcHsiIn7vwJETTJqVRmVVFQunj6RLlDMDDB0NeGttBpDkZBsiIoGkqLScybPTOHysnAXTU+gZ19KxtvxqsjERkWB2rKyCW15ZxZ6Dpbx663AGdW7jaHuaqkBExAdOnKxk6px0Nuw7wvMTE7mwR4zjbSrgRUQcVl5RxS9S17Bi90GevGEwVwxo75N2FfAiIg6qrLL8alEGX2zJ57+vuYBrEjv5rG0FvIiIQ6qqLP/x1no+2JDLQ2P7cVNyvE/bV8CLiDjAWsvv39/Em6v3cu9lvZg2OsHnNSjgRUQc8PgnW5mzPIupo7oz4/JertSggBcRaWB//XIHf/tqJxNHxPPQj/phjHGlDgW8iEgDevUfu3n8k62MH9KRP14z0LVwBwW8iEiDeT09h0fe38yY/u144obBhDRxL9xBAS8i0iCWrN/Pg2+t5we9Ynj+pkTCQtyPV/crEBEJcF9syWPGwgyGdW3LizcPo2loiNslAQp4EZHz8u32Au6Yt4Z+HVox65bhRIT7zxRfCngRkXP03c5Cps5JJyEmkrm3jaBVszC3S/oeBbyIyDlYufsQU15NJz4qgtSpybSNDHe7pH+hgBcRqafVWYe59ZWVdGjTjNRpyUS3aOp2STVSwIuI1MO6nCJumb2S2JZNWTAthbiWzdwuqVYKeBGROtq47wg3z0qjTWQY86el0K6V/4Y7KOBFROokM/cok2al0bJZGPOnptCxTXO3SzorBbyIyFlszytm0stpNAsNYf60ZMcWyW5oCngRkTPYWVDCxJfSaNLEMH9aMl2jI90uqc4U8CIitdhTeIybXloBWBZMSyYhtoXbJdWLAl5EpAY5h0q56aUVlFdUkTo1hZ5xLd0uqd7855paERE/kXOolAkzV3CsvJL505Lp0z7wwh0U8CIi35N9sJQJM5dzrLyS1KnJDOjY2u2SzpmjAW+M2QMUA5VAhbU2ycn2RETOR9bBY0ycuYLSk55wH9gpcMMdfHMEf4m1ttAH7YiInLM9hceY+NIKTpysZP7UFPp3bOV2SedNp2hEpNHbXeg5ci+vrGL+tBT6dQj8cAfnR9FY4FNjzGpjzPSadjDGTDfGpBtj0gsKChwuR0Tk+3YVlDBh5nJvuCcHTbiD8wF/kbV2KHAVcJcxZnT1Hay1M621SdbapNjYWIfLERH5fzsLSpgwcwUVlZYF01Lo2z54wh0cDnhr7X7v93xgMTDCyfZEROpqR74n3KusZcH0lIAdCnkmjgW8MSbSGNPy1G3gCmCjU+2JiNTVjvxiJsxcgbWwYFoKvdsFX7iDsx+ytgMWG2NOtTPfWvuxg+2JiJzV9rxiJr60AmMMC6al0DMusKYfqA/HAt5auwsY7NTPFxGpr60HivnZy40j3EFz0YhII7Fx3xF+OnM5IU0MC6cHf7iDAl5EGoHVWYeZ+NIKIsNDef32kfQIsFkhz5UudBKRoLZ850GmzFlFXMumpE5LoVMArMTUUBTwIhK0vt5WwPS56cRHRZA6NZk4P19DtaEp4EUkKC3dnMddqWvoEdeCeVNGEN2iqdsl+ZwCXkSCzpL1+5mxMIMBnVoz99YRtI4Ic7skV+hDVhEJKm+t3ss9C9aSGN+GeVMab7iDjuBFJIikpmXx0OKNXNQzmpcmJxER3rgjrnH/60UkaMxatptHl2zm0r5x/O1nQ2kWFuJ2Sa5TwItIwPvrlzt4/JOtXDWwPc9MSCQ8VGefQQEvIgHMWstjH2/hxa93cc2Qjjxxw2BCQxTupyjgRSQgVVZZfvvOBhaszGFSSjx/uHogTZoYt8vyKwp4EQk45RVV/Or1DD5Yn8tdl/Tgviv64J25Vk6jgBeRgHK8vJI75q3m620F/GZsX6aP7uF2SX5LAS8iAePI8ZNMeXUVa7IP8+efXMBPh8e7XZJfU8CLSEAoKC5j8uyV7Mgv5vmbhjL2gg5ul+T3FPAi4vf2Hi5l0stp5B0tY9bPhzO6d6zbJQUEBbyI+LUd+cVMenklpeUVzJuazLCubd0uKWAo4EXEb63fW8TPZ68kpEkTFt0+kn4dWrldUkBRwIuIX1qx6yBT56TTJiKMeVOS6RYT6XZJAUcBLyJ+56MNudy7KIOuURG8NiWZ9q0b10IdDUUBLyJ+5bUVWTz87kYSu7Rh9i3DaRMR7nZJAUsBLyJ+wVrLU0u38dwXO7i8XxzPTRxK83DNCHk+FPAi4rqKyip++85GFq7K4adJXfjvawdq0rAG4HjAG2NCgHRgn7V2nNPtiUhgOV5eyS8XrOWzzDx+eWlPfj2mt+aVaSC+OIK/F8gENL5JRL6nqLScKXPSWZN9mEfHD+Dmkd3cLimoOPo3kDGmM/Aj4GUn2xGRwLO/6DjX/305G/Ye4W83DVW4O8DpI/ingQeAlrXtYIyZDkwHiI/XxEEijcG2vGImz1rJsbIK5k4ZQUpCtNslBSXHjuCNMeOAfGvt6jPtZ62daa1NstYmxcZqfgmRYLdqzyGuf+E7qqzl9TtGKtwd5OQR/EXA1caYsUAzoJUxZp61dpKDbYqIH/t44wHuXbiWTm2bM/e2EXRuG+F2SUHNsSN4a+1/Wms7W2u7AROALxTuIo3XrGW7uTN1Nf07tuLNOy5UuPuAxsGLiKMqqyyPLtnMq9/t4coB7Xl6whCahekCJl/wScBba78CvvJFWyLiP46XV3LPwrUs3ZzHlFHd+c3YfoRoYWyf0RG8iDiioLiMqXNWsX7fER75cX9uuai72yU1Ogp4EWlwOwtKuOWVlRQUl/HipGFcMaC92yU1Sgp4EWlQK3cfYtrcdMJCDAunj2RIlzZul9RoKeBFpMG8t24/972+js5RzXn1lhHER2ukjJsU8CJy3qy1vPD1Tv7y8VZGdI9i5s3DNI+7H1DAi8h5OVlZxcPvbmLBymyuHtyRx28YRNNQDYP0Bwp4ETlnR0pPctf8NSzbUcidF/fg/iv60ETDIP2GAl5EzsmewmPcNmcVOYdK+cv1g7gxqYvbJUk1CngRqbflOw9yZ6pnHsF5U5JJ1oRhfkkBLyL1smhVNg8t3kjX6Ahm3zKcrtGRbpcktVDAi0idVFZZ/vzxFmZ+s4sf9Irh+ZuG0rp5mNtlyRko4EXkrErKKpixcC2fZeYzeWRXHh7XX4tiBwAFvIic0b6i40x5dRXb80v4w/gBTNbSegFDAS8itVqTfZjpc1dTdrKSV24ZzujeWnUtkCjgRaRG72bs4/4319O+VTMWTEumV7tal1YWP6WAF5HvqayyPP7JVv7+9U5GdIvi7zcPIypS0w4EIgW8iPzTkeMnuXfhWr7aWsBNyfE88uMBhIfqw9RApYAXEQB25JcwbW46OYdK+eM1A5mU0tXtkuQ8KeBFhM8z85ixMIPw0CbMn5bCiO5RbpckDUABL9KIWWv521c7eeLTrQzo2IoXb06iU5vmbpclDUQBL9JIlZZXcP8b6/lgQy7jh3TksesG0Txc0/wGEwW8SCOUc6iUaXPT2ZZXzG/G9mXaDxIwRtP8BhsFvEgj893OQu5KXUNlleWVW0fwQ128FLTqFPDGmDjgIqAjcBzYCKRba6scrE1EGpC1llf+sYf//jCT7jGRvDQ5ie4xmgkymJ0x4I0xlwAPAlHAWiAfaAZcA/QwxrwJPGmtPVrDc5sB3wBNve28aa39XYNWLyJ1cqysggff3sD76/Yzpn87nrpxMC2baSbIYHe2I/ixwDRrbXb1DcaYUGAcMAZ4q4bnlgGXWmtLjDFhwDJjzEfW2hXnW7SI1N3OghLueG01OwtKeODKPtwxuoeW1Wskzhjw1tr7z7CtAnjnDNstUOK9G+b9svUvUUTO1ccbD3DfG+sID23Ca1OSuahnjNsliQ/V6RpkY8xrxpjWp93vZoz5vA7PCzHGZOA5tbPUWptWwz7TjTHpxpj0goKCepQuIrWpqKziTx9lcse81fSIa8GSX45SuDdCdZ1kYhmQZowZa4yZBnwKPH22J1lrK621Q4DOwAhjzMAa9plprU2y1ibFxurTfJHzVVhSxs2zVvLi17uYlBLP67en0FEXLzVKdRpFY6190RizCfgSKAQSrbUH6tqItbbIGPMVcCWeETgi4oA12Yf5xbw1HC4t54kbBnP9sM5ulyQuquspmpuB2cBk4FXgQ2PM4LM8J9YY08Z7uzlwObDlfIoVkZpZa5m7fA8/fXE5YaGGt39xocJd6nyh00+AUdbafGCBMWYxnqBPPMNzOgBzjDEheP4jed1au+R8ihWRf1VaXsFvF2/k7bX7uLRvHP974xBaR2gIpNT9FM011e6vNMYkn+U56znzfwAicp625xXzi9Q17Cgo4ddjenP3JT01BFL+6YynaIwxvzXG1DhvqLW23BhzqTFmnDOliciZvLV6L1c//w8Ol5bz2m3J3HNZL4W7fM/ZjuA3AO8bY04Aa4ACPFey9gKGAJ8B/+NkgSLyfcfLK3n43Y28sXovKQlRPDshkbhWzdwuS/zQ2QL+emvtRcaYB/CMZe8AHAXmAdOttcedLlBE/t+OfM8pme35JdxzaU/uvbw3ITpql1qcLeCHGWO6Aj8DLqm2rTmeicdExAfeXrOXhxZvJCI8hLm3jeAHvXTdiJzZ2QL+78DHQAKQftrjBs+0AwkO1SUiXsfLK3nkvU0sSs8huXsUz05MpJ1OyUgdnG0ummeBZ40xL1hr7/RRTSLitSO/mLtS17Itv5hfXtqTey/rRWhIXS9Al8aursMkFe4iPmStZdGqHB55fxOR4aHMuXUEo7Uwh9STVnQS8TNHjp/kN29v4IMNuYzqGcNTNw7WKBk5Jwp4ET+SvucQ9y7MIO/oCR68qi/Tf5Cgse1yzhTwIn6gssry1y938PRn2+gSFcGbd17IkC5t3C5LApwCXsRl+4uOM2NRBit3H+LaxE78YfwALacnDUIBL+Kijzce4D/eWk9FZRVP3TiY64ZqBkhpOAp4EReUllfwxw8ymZ+WzQWdWvPsxES6x0S6XZYEGQW8iI9l5BTxq0UZ7Dl4jNtHJ/DvV/QhPFRj26XhKeBFfKSisornv9zBc1/soH2rZiyYlkJKQrTbZUkQU8CL+MDuwmPMWJTBupwirk3sxO/HD6CVPkgVhyngRRxkrWXByhweXbKZ8NAmPH9TIuMGdXS7LGkkFPAiDikoLuPBt9bz+ZZ8RvWM4YkbBtO+ta5IFd9RwIs4YOnmPB58az3FZRU8PK4/t1zYTVekis8p4EUa0JHSk/x+ySbeXrOPfh1asWDCEHq3a+l2WdJIKeBFGsiXW/N58K31FJaUc8+lPbn70l4a/iiuUsCLnKfiEyf545JMFqXn0CuuBS9NTmJQ5zZulyWigBc5H8u2F/LAm+s4cPQEd/ywBzMu70WzsBC3yxIBFPAi5+RYWQV/+iiTeSuySYiN5M07L2RofFu3yxL5HscC3hjTBZgLtAeqgJnW2mecak/EV1bsOsj9b65j7+HjTB3Vnfv+rY+O2sUvOXkEXwH8u7V2jTGmJbDaGLPUWrvZwTZFHFN84iSPfbSF1LRsukZH8PrtIxneLcrtskRq5VjAW2tzgVzv7WJjTCbQCVDAS8D5PDOP376zkbyjJ5g6qju/vqI3EeE6wyn+zSfvUGNMNyARSKth23RgOkB8fLwvyhGps4MlZfz+/c28t24/fdq15IVJw7TSkgQMxwPeGNMCeAuYYa09Wn27tXYmMBMgKSnJOl2PSF1Ya3k3Yz+/f38TJWUV/Ory3tx5cQ+Na5eA4mjAG2PC8IR7qrX2bSfbEmko+4uO89DiDXy5tYDE+Db8+SeDdDWqBCQnR9EYYBaQaa19yql2RBpKVZUlNS2Lxz7aQpWFh8f15+cXdiNEc8hIgHLyCP4i4GZggzEmw/vYb6y1HzrYpsg5ycw9ym8Wb2BtdhGjesbwp+suoEtUhNtliZwXJ0fRLAN06CN+rbS8gqc/286sZbtp0zyMp24czLWJnfD8ASoS2DTOSxqtzzbn8bv3NrGv6DgThnfhwav60iYi3O2yRBqMAl4andwjx3nkvU18simP3u1a8MYdumBJgpMCXhqNisoq5izP4qlPt1JpLQ9c2YepoxI09FGClgJeGoW12Yf5r3c3snHfUS7uE8uj4wfqQ1QJegp4CWoHS8r488dbeD19L3Etm/LXm4Yy9oL2+hBVGgUFvASlisoqUtOyefLTrZSWV3L76AR+eVkvWjTVW14aD73bJeis2nOIh9/dRGbuUUb1jOGRqwfQM66F22WJ+JwCXoJG/tET/OmjLSxeu4+OrZvxws+GcuVAnY6RxksBLwHvZGUVc77bw9Ofbae8ooq7L+nJLy7poel8pdHTb4AELGstX27N548fZLKr4BgX94nldz8eQPeYSLdLE/ELCngJSNvyinl0yWa+3V5IQkwkL09O4rJ+cTodI3IaBbwElEPHyvnfpduYvzKbyPAQ/mtcf25O6aqLlURqoICXgFBeUcXc5Xt45vPtlJZXMik5nhmX96ZtpOaOEamNAl78mrWWpZvz+J8PM9lzsJSL+8Ty0Nh+9NICHCJnpYAXv7Uup4g/fZTJil2H6BnXglduHc4lfeLcLkskYCjgxe9kHTzGXz7Zygfrc4mODOcP4wcwcUQ8YSE6zy5SHwp48RuFJWU89/l2UtOyCQtpwj2X9mTa6ARaNgtzuzSRgKSAF9eVllfw8re7mfnNLo6frOSnw7sw47JexLVq5nZpIgFNAS+uqaisYlF6Dk9/tp2C4jL+bUA7HriyLz1iNW+MSENQwIvPVVVZPtiQy/9+to1dBcdI6tqWv08ayrCuWlVJpCEp4MVnTg15fGrpNrYcKKZ3uxbMvHkYY/q30xWoIg5QwIvjrLV8u72QJz/dyrq9R+geE8kzE4YwblBHQpoo2EWcooAXR6XtOsiTn25j5Z5DdGrTnL9cP4jrEjsRqiGPIo5TwIsjMnKKePLTrXy7vZC4lk15dPwAbhzehaahIW6XJtJoKOClQa3OOsxzX2znq60FREWG89DYfkxK6UrzcAW7iK85FvDGmNnAOCDfWjvQqXbEP6TtOshzX+xg2Y5CoiLDeeDKPkwe2U1roIq4yMnfvleB54G5DrYhLrLWsnznQZ75fDtpuw8R06IpD43tx89S4rWakogfcOy30Fr7jTGmm1M/X9xzalTMs59vJz3rMO1aNeV3P+7PxBHxNAvTqRgRf+H6YZYxZjowHSA+Pt7lauRMqqosSzPzeOGrnWTkFNGxdTMeHT+AG5K6KNhF/JDrAW+tnQnMBEhKSrIulyM1KKuo5J21+3jxm13sKjhGl6jm/Om6C/jJ0M5aSUnEj7ke8OK/ik+cZH5aNrP/sZu8o2UM6NiK5yYmctXA9hrHLhIAFPDyL/KLT/DKP/Ywb0UWxScquKhnNE/cMJhRPWM0pYBIAHFymOQC4GIgxhizF/idtXaWU+3J+dtZUMLL3+7mrTV7OVlZxdiBHbj9hwkM6tzG7dJE5Bw4OYpmolM/WxqOtZZlOwqZvWw3X24tIDy0CT8Z2pnpoxPoHhPpdnkich50iqaROnHS88Hp7H/sZlteCTEtmvKry3tzU3I8sS2bul2eiDQABXwjk3/0BK+tyCI1LZtDx8rp36EVT9wwmB8P7qB5YkSCjAK+kViXU8Sr3+1hyfr9VFRZxvRrx22jupPcPUofnIoEKQV8EDteXsn76/YzLy2L9XuPEBkewqSUrtxyYTe6Ruv8ukiwU8AHoV0FJaSmZfNGeg5HT1TQu10LHh0/gGsSO9GyWZjb5YmIjyjgg0RFZRWfZeYxb0U2y3YUEhZiuHJgByYlxzNCp2FEGiUFfIDbe7iUN9L3smhVDgeOnqBj62bcd0VvbhzehbiWzdwuT0RcpIAPQGUVlXy6KY/X03NYtqMQgFE9Y/jD+AFc2jdO0wiICKCADyiZuUdZtCqHdzL2UVR6kk5tmnPPpb24IakzndtGuF2eiPgZBbyfO3riJO9l7Of19BzW7z1CeEgTxgxox0+TunBRzxhCmujcuojUTAHvh8orqvhmWwGLM/bx2eY8yiqq6Nu+JQ+P68+1iZ1oGxnudokiEgAU8H7CWsvanCLeWbuP99ft53DpSaIiw5kwvAvXDe3MoM6tNRJGROpFAe+y3YXHeGftPt7J2EfWwVKahjZhTP92XJvYidG9YwnTB6Yico4U8C7YX3ScDzfksmR9Lhk5RRgDIxOiufuSnlw5sL0uRhKRBqGA95HcI8f5cMMBPli/nzXZRQD079CK/7yqL1cP6UiH1s3dLVBEgo4C3kEHjpzgww25fLAhl9VZhwFPqN//b30Ye0EHzbcuIo5SwDewPYXHWLo5j082HSDdG+r9OrTivit6M/aCDiTEtnC5QhFpLBTw56mqypKxt4ilm/P4bHMe2/NLAE+o//uY3owd1IEeCnURcYEC/hycOFnJdzsLPaGemU9BcRkhTQzJ3aO4KTmey/u1o0uUriwVEXcp4Oso51ApX28r4KutBXy3s5DS8koiw0O4uE8cY/q345I+cbSO0OgXEfEfCvhanDhZSdruQ3y9tYCvtuWzq+AYAJ3bNue6oZ24vF87RvaI1jJ3IuK3FPBe1lp2FpTw7fZCvtpawIpdBymrqCI8tAkpCdFMSu7KD/vEkhATqStKRSQgNNqAt9aSfaiU5TsP8t3OgyzfdZCC4jIAEmIimTginov7xJLcPZrm4TpKF5HA06gCPvfIcb7b4Qnz5TsPsq/oOACxLZsyMiGaC3tEc2GPGOKj9QGpiAQ+RwPeGHMl8AwQArxsrX3MyfZOV1Vl2Z5fQnrWIVbvOUx61mGyD5UC0DYijJSEaO74YQIje0TTI7aFTruISNBxLOCNMSHAX4ExwF5glTHmPWvtZifaO15eSUZOEauzDpGedZg1WYc5eqICgJgW4Qzr2pbJI7tyYY8Y+rZvSRPNoy4iQc7JI/gRwA5r7S4AY8xCYDzQoAFfVlHJjS+uYNO+I1RUWQB6xbXgR4M6MKxrFEld29I1OkJH6CLS6DgZ8J2AnNPu7wWSq+9kjJkOTAeIj4+vdyNNQ0PoHh3BRT2iSerWlqHxbWkToQUxREScDPiaDpntvzxg7UxgJkBSUtK/bK+LpycknsvTRESCmpOrSewFupx2vzOw38H2RETkNE4G/CqglzGmuzEmHJgAvOdgeyIichrHTtFYayuMMXcDn+AZJjnbWrvJqfZEROT7HB0Hb639EPjQyTZERKRmWtFZRCRIKeBFRIKUAl5EJEgp4EVEgpSx9pyuLXKEMaYAyDrHp8cAhQ1YTkNRXfXnr7WprvpRXfV3LrV1tdbG1rTBrwL+fBhj0q21SW7XUZ3qqj9/rU111Y/qqr+Grk2naEREgpQCXkQkSAVTwM90u4BaqK7689faVFf9qK76a9DaguYcvIiIfF8wHcGLiMhpFPAiIkEqoALeGHOlMWarMWaHMebBGrYbY8yz3u3rjTFDfVRXF2PMl8aYTGPMJmPMvTXsc7Ex5ogxJsP79bCPattjjNngbTO9hu0+7zNjTJ/T+iHDGHPUGDOj2j4+6y9jzGxjTL4xZuNpj0UZY5YaY7Z7v7et5blnfE86UNfjxpgt3tdqsTGmTS3PPePr7kBdjxhj9p32eo2t5bm+7q9Fp9W0xxiTUctzneyvGvPBJ+8xa21AfOGZcngnkACEA+uA/tX2GQt8hGc1qRQgzUe1dQCGem+3BLbVUNvFwBIX+m0PEHOG7a70WbXX9QCeizVc6S9gNDAU2HjaY38BHvTefhD4cy21n/E96UBdVwCh3tt/rqmuurzuDtT1CHBfHV5rn/ZXte1PAg+70F815oMv3mOBdAT/z0W8rbXlwKlFvE83HphrPVYAbYwxHZwuzFqba61d471dDGTiWZM2ELjSZ6e5DNhprT3XK5jPm7X2G+BQtYfHA3O8t+cA19Tw1Lq8Jxu0Lmvtp9baCu/dFXhWSvOpWvqrLnzeX6cYYwxwI7CgodqrqzPkg+PvsUAK+JoW8a4eonXZx1HGmG5AIpBWw+aRxph1xpiPjDEDfFSSBT41xqw2ngXOq3O7zyZQ+y+dG/11SjtrbS54fkGBuBr2cbvvbsPz11dNzva6O+Fu76mj2bWcbnCzv34A5Flrt9ey3Sf9VS0fHH+PBVLA12UR7zot9O0UY0wL4C1ghrX2aLXNa/CchhgMPAe846OyLrLWDgWuAu4yxoyutt21PjOepRyvBt6oYbNb/VUfbvbdQ0AFkFrLLmd73RvaC0APYAiQi+d0SHVu/n5O5MxH747311nyodan1fBYnfsskAK+Lot4u7bQtzEmDM+Ll2qtfbv6dmvtUWttiff2h0CYMSbG6bqstfu93/OBxXj+5Dudm4ujXwWssdbmVd/gVn+dJu/UqSrv9/wa9nGl74wxPwfGAT+z3hO11dXhdW9Q1to8a22ltbYKeKmW9tzqr1DgOmBRbfs43V+15IPj77FACvi6LOL9HjDZOzIkBThy6k8gJ3nP780CMq21T9WyT3vvfhhjRuDp+4MO1xVpjGl56jaeD+g2VtvNlT7zqvWoyo3+quY94Ofe2z8H3q1hH58vLG+MuRL4D+Bqa21pLfvU5XVv6LpO/9zm2lra83l/eV0ObLHW7q1po9P9dYZ8cP495sSnxk594RnxsQ3Pp8oPeR+7A7jDe9sAf/Vu3wAk+aiuUXj+bFoPZHi/xlar7W5gE55PwVcAF/qgrgRve+u8bftTn0XgCezWpz3mSn/h+U8mFziJ54hpChANfA5s936P8u7bEfjwTO9Jh+vageec7Kn32d+r11Xb6+5wXa953z/r8QRQB3/oL+/jr556X522ry/7q7Z8cPw9pqkKRESCVCCdohERkXpQwIuIBCkFvIhIkFLAi4gEKQW8iEiQUsCL1MI7C+BuY0yU935b7/2ubtcmUhcKeJFaWGtz8FyC/5j3oceAmdbFidFE6kPj4EXOwHuJ+WpgNjANSLSeWf1E/F6o2wWI+DNr7UljzP3Ax8AVCncJJDpFI3J2V+G5BH6g24WI1IcCXuQMjDFDgDF4Vrv6lY8XQxE5Lwp4kVp4ZwF8Ac/83dnA48AT7lYlUncKeJHaTQOyrbVLvff/BvQ1xvzQxZpE6kyjaEREgpSO4EVEgpQCXkQkSCngRUSClAJeRCRIKeBFRIKUAl5EJEgp4EVEgtT/AU7VB8fCPUM/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# 0~20까지 0.1 간격 배열의 x\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50cd4091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999999999908982e-09"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = 5\n",
    "\n",
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e55358f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.999999999986347e-09"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = 10\n",
    "\n",
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137a319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 for 편미분\n",
    "# y = x0^2 + x1^2\n",
    "\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c990d2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.000000000003781e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 = 3, x1 = 4일 때 x0에 대한 편미분계수\n",
    "# x1값 상수취급\n",
    "\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "numerical_diff(function_tmp1, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36f77859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.999999999999119e-08"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x0 = 3, x1 = 4 일 때 x1에 대한 편미분계수\n",
    "# x0값 상수취급\n",
    "\n",
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "numerical_diff(function_tmp2, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7078a",
   "metadata": {},
   "source": [
    "## 4.4. 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bbe2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기울기 구현\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)    # x와 같은 shape 배열, 0으로 채움\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x+h)\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h)\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2)/(2*h)\n",
    "        x[idx] = tmp_val      # 값 복원\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d5b14ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3,4)\n",
    "\n",
    "numerical_gradient(function_2, np.array([3.0,4.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc6c520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0,2)\n",
    "\n",
    "numerical_gradient(function_2, np.array([0.0, 2.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f9cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3,0)\n",
    "\n",
    "numerical_gradient(function_2, np.array([3.0, 0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d8f7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr * grad\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "531fea84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f(x0, x1) = x0^2 + x1^2 최솟값 구하기\n",
    "\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec87dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 너무 크면\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd390119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률 너무 작으면 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87929cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_simplent.py\n",
    "\n",
    "import sys, os\n",
    "# sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 하위 디렉토리에 common 폴더 안에 Ch3부터 만든 함수들 넣어두고\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y,t)\n",
    "    \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f4c214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9e5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c03ea846",
   "metadata": {},
   "source": [
    "## 4.5. 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a7222a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2층 신경망 클래스\n",
    "\n",
    "import sys, os\n",
    "# sys.path.append(os.pardir)\n",
    "\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size,hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        \n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # x: 입력데이터\n",
    "    # t: 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    # gradient\n",
    "    def numerical_gradient(self, x, t):\n",
    "        # loss function\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23f5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# 예시\n",
    "\n",
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfb9118e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09780667, 0.10507606, 0.10466475, 0.09977941, 0.09108513,\n",
       "        0.10051071, 0.0961527 , 0.10623715, 0.10184363, 0.0968438 ],\n",
       "       [0.09775421, 0.10506983, 0.1045852 , 0.09998866, 0.09085307,\n",
       "        0.10009818, 0.09677391, 0.10608821, 0.10143692, 0.09735182],\n",
       "       [0.09770489, 0.10473137, 0.10499407, 0.10005876, 0.09081502,\n",
       "        0.10021762, 0.09643362, 0.10607399, 0.10158995, 0.09738072],\n",
       "       [0.09767249, 0.10509975, 0.1043802 , 0.09996682, 0.09074186,\n",
       "        0.10039448, 0.09635894, 0.1059919 , 0.10167505, 0.09771852],\n",
       "       [0.09747825, 0.10543417, 0.104512  , 0.09981764, 0.09106506,\n",
       "        0.10025373, 0.09647389, 0.10635074, 0.10148555, 0.09712898],\n",
       "       [0.09762447, 0.10525363, 0.10436676, 0.09951319, 0.09086599,\n",
       "        0.10028368, 0.09643758, 0.10629731, 0.10154275, 0.09781464],\n",
       "       [0.09741043, 0.105173  , 0.10414166, 0.10014444, 0.09098623,\n",
       "        0.10050211, 0.09639515, 0.10640412, 0.10123088, 0.09761197],\n",
       "       [0.09790734, 0.10503647, 0.10425915, 0.09974179, 0.09063031,\n",
       "        0.10034032, 0.09635019, 0.10636134, 0.10188525, 0.09748784],\n",
       "       [0.09748465, 0.1053666 , 0.10489747, 0.10020279, 0.09073401,\n",
       "        0.10003856, 0.09646994, 0.10593418, 0.10148921, 0.0973826 ],\n",
       "       [0.09758151, 0.10491698, 0.10466471, 0.1000324 , 0.09087516,\n",
       "        0.10018752, 0.09638674, 0.10632622, 0.10144276, 0.097586  ],\n",
       "       [0.09776653, 0.10513317, 0.10467387, 0.10001019, 0.09076304,\n",
       "        0.10006682, 0.09675296, 0.10626584, 0.10137649, 0.09719109],\n",
       "       [0.09774849, 0.10475426, 0.104399  , 0.09986051, 0.09071635,\n",
       "        0.10004165, 0.09692429, 0.10631048, 0.10189643, 0.09734853],\n",
       "       [0.09797664, 0.10500074, 0.10448009, 0.09987823, 0.09086478,\n",
       "        0.10036974, 0.09637558, 0.10627843, 0.1014893 , 0.09728648],\n",
       "       [0.09773752, 0.10491476, 0.10430939, 0.09969414, 0.09093778,\n",
       "        0.10053701, 0.09639019, 0.10619022, 0.10171221, 0.09757679],\n",
       "       [0.09778582, 0.10491512, 0.10468371, 0.09964609, 0.09096773,\n",
       "        0.10059015, 0.09649072, 0.1060881 , 0.10152974, 0.09730282],\n",
       "       [0.09756134, 0.10496132, 0.10476345, 0.10024128, 0.09082752,\n",
       "        0.10043   , 0.09643117, 0.10615971, 0.10154353, 0.09708069],\n",
       "       [0.09786769, 0.10483841, 0.10455402, 0.09997335, 0.09060302,\n",
       "        0.10030104, 0.09652635, 0.10640802, 0.10139633, 0.09753178],\n",
       "       [0.09763516, 0.10500314, 0.10471133, 0.10004288, 0.09053805,\n",
       "        0.1005775 , 0.09636242, 0.10615229, 0.10123275, 0.09774449],\n",
       "       [0.0976107 , 0.10497749, 0.104526  , 0.09964985, 0.09076788,\n",
       "        0.10019589, 0.0966172 , 0.10621596, 0.10193362, 0.09750541],\n",
       "       [0.09758987, 0.10485259, 0.10451539, 0.10004798, 0.0909357 ,\n",
       "        0.10030563, 0.09655447, 0.10641008, 0.101599  , 0.0971893 ],\n",
       "       [0.09778318, 0.1049337 , 0.10448724, 0.09990346, 0.0910206 ,\n",
       "        0.10049203, 0.09644204, 0.10598301, 0.10144082, 0.09751391],\n",
       "       [0.09724794, 0.10512916, 0.10433314, 0.09992422, 0.09089947,\n",
       "        0.10021352, 0.09653364, 0.10653729, 0.10173666, 0.09744497],\n",
       "       [0.09750284, 0.10497969, 0.10465762, 0.09983841, 0.09093869,\n",
       "        0.10073304, 0.09650356, 0.1060602 , 0.10160729, 0.09717866],\n",
       "       [0.09766115, 0.10493539, 0.10453098, 0.09990318, 0.0909543 ,\n",
       "        0.10018022, 0.09650345, 0.10617523, 0.10158486, 0.09757125],\n",
       "       [0.09771237, 0.10508687, 0.10448792, 0.09986573, 0.09105623,\n",
       "        0.10020289, 0.09628143, 0.10624418, 0.10146341, 0.09759898],\n",
       "       [0.09747168, 0.10519809, 0.10445227, 0.09989475, 0.09115722,\n",
       "        0.10021188, 0.09649796, 0.10632864, 0.10162388, 0.09716362],\n",
       "       [0.09770633, 0.10494089, 0.10469357, 0.09947063, 0.09100488,\n",
       "        0.10049647, 0.09678733, 0.10615732, 0.10164899, 0.09709358],\n",
       "       [0.09811062, 0.10485339, 0.10437991, 0.0998272 , 0.09086616,\n",
       "        0.0998909 , 0.09672165, 0.10615373, 0.10163113, 0.0975653 ],\n",
       "       [0.09761429, 0.10497437, 0.1043135 , 0.09999621, 0.09097648,\n",
       "        0.09999927, 0.0965486 , 0.10615796, 0.10131763, 0.0981017 ],\n",
       "       [0.09773503, 0.10481284, 0.10467447, 0.09993986, 0.09080548,\n",
       "        0.10019275, 0.09648255, 0.10625994, 0.10148117, 0.0976159 ],\n",
       "       [0.09784402, 0.10501507, 0.10415563, 0.09970229, 0.09104997,\n",
       "        0.10018144, 0.09638689, 0.10641066, 0.10161932, 0.09763469],\n",
       "       [0.09791993, 0.10485306, 0.1046323 , 0.09993363, 0.09072017,\n",
       "        0.10017641, 0.09653784, 0.1064739 , 0.10129585, 0.09745691],\n",
       "       [0.09806539, 0.10478309, 0.10459345, 0.09959927, 0.09080791,\n",
       "        0.10031198, 0.09650663, 0.10617035, 0.10166932, 0.09749261],\n",
       "       [0.09771365, 0.10480309, 0.10421591, 0.09981394, 0.09108419,\n",
       "        0.1004987 , 0.0963804 , 0.10609276, 0.10183489, 0.09756247],\n",
       "       [0.0977029 , 0.10498687, 0.10449629, 0.1000136 , 0.09096066,\n",
       "        0.09992447, 0.09646896, 0.10613054, 0.10169864, 0.09761707],\n",
       "       [0.09779456, 0.10488981, 0.10478751, 0.10010176, 0.09105312,\n",
       "        0.09998541, 0.09630598, 0.10588423, 0.1015705 , 0.09762712],\n",
       "       [0.097797  , 0.10476408, 0.10472106, 0.10001786, 0.0908673 ,\n",
       "        0.10003076, 0.09641848, 0.1062941 , 0.10171144, 0.09737792],\n",
       "       [0.09757248, 0.10510498, 0.10482575, 0.10004221, 0.09126146,\n",
       "        0.10006582, 0.09649702, 0.10626473, 0.10122106, 0.09714449],\n",
       "       [0.09738406, 0.10493966, 0.1047782 , 0.09955141, 0.09120498,\n",
       "        0.10069662, 0.0965311 , 0.10586301, 0.10152598, 0.09752497],\n",
       "       [0.09725941, 0.10516953, 0.10461344, 0.09992966, 0.09091873,\n",
       "        0.10029887, 0.0964217 , 0.10617678, 0.10153348, 0.09767841],\n",
       "       [0.09766334, 0.10508229, 0.10461081, 0.09987743, 0.09084087,\n",
       "        0.10010896, 0.09635317, 0.10646775, 0.1015183 , 0.09747708],\n",
       "       [0.09780654, 0.10486157, 0.10435634, 0.1002398 , 0.09085751,\n",
       "        0.10006399, 0.09671978, 0.10611976, 0.10152216, 0.09745254],\n",
       "       [0.09774823, 0.104929  , 0.10435478, 0.10011087, 0.09085947,\n",
       "        0.10042016, 0.09670877, 0.10627006, 0.10127324, 0.09732542],\n",
       "       [0.09747192, 0.10505155, 0.10455314, 0.09963284, 0.09102729,\n",
       "        0.10037428, 0.09639868, 0.10638812, 0.10187217, 0.09723002],\n",
       "       [0.09795488, 0.10475366, 0.10444158, 0.09964844, 0.09118267,\n",
       "        0.10038745, 0.0965962 , 0.10642477, 0.10158399, 0.09702635],\n",
       "       [0.09747571, 0.10475239, 0.10445188, 0.09992114, 0.09134295,\n",
       "        0.10032839, 0.0963159 , 0.10614121, 0.10158372, 0.09768671],\n",
       "       [0.09767403, 0.1048549 , 0.10488754, 0.09969798, 0.09079355,\n",
       "        0.10045101, 0.09645545, 0.10607062, 0.10148048, 0.09763445],\n",
       "       [0.09759968, 0.10468208, 0.10461924, 0.09987193, 0.09114648,\n",
       "        0.10033184, 0.09662775, 0.10635362, 0.10142461, 0.09734276],\n",
       "       [0.09808469, 0.10484493, 0.10455094, 0.09955215, 0.09085761,\n",
       "        0.10001353, 0.09670081, 0.10640784, 0.1018411 , 0.0971464 ],\n",
       "       [0.09797904, 0.10526513, 0.10464161, 0.09961842, 0.09071512,\n",
       "        0.10024407, 0.09655743, 0.10648017, 0.10117412, 0.0973249 ],\n",
       "       [0.09781117, 0.10474556, 0.10476034, 0.0999154 , 0.09093024,\n",
       "        0.10019589, 0.09630042, 0.10622935, 0.10157191, 0.09753971],\n",
       "       [0.09783135, 0.10503982, 0.10454583, 0.10003126, 0.09087741,\n",
       "        0.10026846, 0.09636733, 0.10599083, 0.10156364, 0.09748408],\n",
       "       [0.09735971, 0.10509715, 0.10444117, 0.1000925 , 0.09085501,\n",
       "        0.10038145, 0.09653927, 0.10604444, 0.10187634, 0.09731297],\n",
       "       [0.09773659, 0.10489627, 0.10467525, 0.1000051 , 0.09084741,\n",
       "        0.10064169, 0.09615647, 0.10622031, 0.1015593 , 0.09726161],\n",
       "       [0.09785964, 0.10466798, 0.10478287, 0.10002729, 0.09063877,\n",
       "        0.10019721, 0.09624489, 0.1062739 , 0.10170113, 0.09760632],\n",
       "       [0.09793887, 0.10492233, 0.10441956, 0.09987997, 0.09079389,\n",
       "        0.10038804, 0.09603565, 0.10655549, 0.10158619, 0.09748   ],\n",
       "       [0.09763424, 0.1049423 , 0.1045558 , 0.09987877, 0.09090075,\n",
       "        0.10031494, 0.09631014, 0.10637626, 0.10179746, 0.09728932],\n",
       "       [0.09783009, 0.10467252, 0.10454445, 0.10007231, 0.0911833 ,\n",
       "        0.10035951, 0.09636721, 0.10642943, 0.10119016, 0.09735103],\n",
       "       [0.09778423, 0.10481289, 0.10466514, 0.10009506, 0.0907996 ,\n",
       "        0.1004904 , 0.09632988, 0.10632979, 0.10164481, 0.0970482 ],\n",
       "       [0.09787909, 0.10473332, 0.10477937, 0.10008739, 0.09091732,\n",
       "        0.1002316 , 0.09636653, 0.10608499, 0.10148984, 0.09743055],\n",
       "       [0.09802818, 0.10489892, 0.10432957, 0.09993449, 0.0907946 ,\n",
       "        0.10010131, 0.09655885, 0.10657553, 0.10161429, 0.09716428],\n",
       "       [0.09795088, 0.10493969, 0.10467677, 0.09949378, 0.09082444,\n",
       "        0.10036583, 0.09648154, 0.10636564, 0.10152329, 0.09737813],\n",
       "       [0.0979142 , 0.10485335, 0.10447179, 0.09993301, 0.0909714 ,\n",
       "        0.10027685, 0.0965065 , 0.10635961, 0.10157665, 0.09713663],\n",
       "       [0.0981675 , 0.10470164, 0.10460226, 0.09966678, 0.09126719,\n",
       "        0.10020558, 0.09630153, 0.10606199, 0.10175471, 0.09727082],\n",
       "       [0.09791491, 0.10484423, 0.10500399, 0.09988991, 0.09070618,\n",
       "        0.10033869, 0.0962292 , 0.1062049 , 0.10143183, 0.09743617],\n",
       "       [0.09781844, 0.10485193, 0.10469104, 0.10003458, 0.09102924,\n",
       "        0.10008787, 0.09656261, 0.10640854, 0.10130027, 0.09721547],\n",
       "       [0.0976455 , 0.1047656 , 0.10449175, 0.10013378, 0.09092593,\n",
       "        0.10015168, 0.09667462, 0.10636489, 0.1016574 , 0.09718886],\n",
       "       [0.09773726, 0.10497907, 0.10488766, 0.09993303, 0.09071993,\n",
       "        0.10002069, 0.09603104, 0.1064235 , 0.10185053, 0.09741729],\n",
       "       [0.09767395, 0.10518393, 0.1049163 , 0.09981104, 0.09070593,\n",
       "        0.09999372, 0.09645196, 0.10623463, 0.10192658, 0.09710197],\n",
       "       [0.09752876, 0.10501174, 0.1045803 , 0.09988239, 0.09079167,\n",
       "        0.10053149, 0.09655612, 0.10600511, 0.10155312, 0.09755932],\n",
       "       [0.0979501 , 0.10455597, 0.10503595, 0.09967502, 0.09084473,\n",
       "        0.10026056, 0.09649038, 0.10639423, 0.10154141, 0.09725164],\n",
       "       [0.09789706, 0.10483463, 0.10401272, 0.0996298 , 0.09111986,\n",
       "        0.10014095, 0.09648035, 0.10619115, 0.10220436, 0.09748911],\n",
       "       [0.09747674, 0.10518809, 0.10474086, 0.09979669, 0.09092684,\n",
       "        0.10028306, 0.09658038, 0.10621437, 0.10118752, 0.09760546],\n",
       "       [0.09755697, 0.10496086, 0.10451004, 0.09988058, 0.09064609,\n",
       "        0.10027627, 0.09665954, 0.10651368, 0.10143645, 0.09755953],\n",
       "       [0.09763449, 0.10527209, 0.10435932, 0.09972722, 0.09114481,\n",
       "        0.10002447, 0.09654825, 0.10624029, 0.10127095, 0.09777811],\n",
       "       [0.09773765, 0.10493749, 0.10442455, 0.09988943, 0.09102892,\n",
       "        0.1002862 , 0.09653288, 0.10597751, 0.10177997, 0.0974054 ],\n",
       "       [0.09781844, 0.10523496, 0.1044494 , 0.10001424, 0.09085229,\n",
       "        0.1000467 , 0.09652376, 0.10653602, 0.10151681, 0.0970074 ],\n",
       "       [0.09783251, 0.10487438, 0.10466165, 0.10011956, 0.09098261,\n",
       "        0.10015091, 0.09639449, 0.10647793, 0.10117834, 0.09732763],\n",
       "       [0.0975502 , 0.10471586, 0.10470697, 0.10006604, 0.09074886,\n",
       "        0.10020618, 0.09652429, 0.10635272, 0.10153192, 0.09759696],\n",
       "       [0.09768319, 0.10491318, 0.10472019, 0.09999342, 0.09090996,\n",
       "        0.1005044 , 0.09611946, 0.10603456, 0.10165023, 0.09747141],\n",
       "       [0.09763177, 0.10505934, 0.10472869, 0.09995312, 0.09081623,\n",
       "        0.10035117, 0.09659549, 0.10631121, 0.10122767, 0.0973253 ],\n",
       "       [0.09732765, 0.105041  , 0.10498022, 0.10010385, 0.09093357,\n",
       "        0.1003861 , 0.09621451, 0.10599629, 0.10169726, 0.09731953],\n",
       "       [0.09744637, 0.10512463, 0.10466949, 0.10021326, 0.09084447,\n",
       "        0.09990851, 0.09664826, 0.10634967, 0.10130656, 0.09748878],\n",
       "       [0.09787989, 0.10506383, 0.10414031, 0.09962206, 0.09100321,\n",
       "        0.10041658, 0.09656837, 0.10612832, 0.10158882, 0.09758861],\n",
       "       [0.0977445 , 0.10492753, 0.10445185, 0.09994811, 0.09090972,\n",
       "        0.1003652 , 0.0964872 , 0.10628626, 0.10171162, 0.097168  ],\n",
       "       [0.0979034 , 0.10472921, 0.10445469, 0.10016171, 0.09066222,\n",
       "        0.10016846, 0.09663497, 0.10613064, 0.10169108, 0.09746362],\n",
       "       [0.09747698, 0.10494084, 0.10473096, 0.09977871, 0.09101069,\n",
       "        0.10052534, 0.0961261 , 0.10603555, 0.10176103, 0.0976138 ],\n",
       "       [0.09774304, 0.10504879, 0.10432967, 0.09979051, 0.09114723,\n",
       "        0.10041769, 0.09651104, 0.10605589, 0.1012479 , 0.09770824],\n",
       "       [0.09769011, 0.10492782, 0.1049219 , 0.09945038, 0.09104859,\n",
       "        0.10012056, 0.09643426, 0.1061166 , 0.1014078 , 0.09788196],\n",
       "       [0.09758176, 0.10521789, 0.10473891, 0.09992664, 0.09072758,\n",
       "        0.10036888, 0.09665343, 0.10589341, 0.10151754, 0.09737396],\n",
       "       [0.09804966, 0.10486841, 0.1045448 , 0.09973197, 0.09076405,\n",
       "        0.10026417, 0.09650203, 0.10646249, 0.10143293, 0.09737949],\n",
       "       [0.09769206, 0.10474111, 0.10436456, 0.09995357, 0.09113538,\n",
       "        0.10030898, 0.09627509, 0.10622679, 0.1018486 , 0.09745386],\n",
       "       [0.0976684 , 0.10491627, 0.10460224, 0.10005534, 0.09089667,\n",
       "        0.09986159, 0.09645434, 0.10582268, 0.10180598, 0.09791649],\n",
       "       [0.09792595, 0.10499983, 0.10467916, 0.10010514, 0.09075874,\n",
       "        0.1000595 , 0.09629831, 0.10630883, 0.10148056, 0.09738399],\n",
       "       [0.09808284, 0.10490281, 0.10478959, 0.09962983, 0.09080352,\n",
       "        0.10012782, 0.09666599, 0.1063682 , 0.10139381, 0.09723559],\n",
       "       [0.09782108, 0.10492341, 0.10466204, 0.10009224, 0.09052102,\n",
       "        0.09994882, 0.09645783, 0.10631569, 0.10175301, 0.09750486],\n",
       "       [0.09787388, 0.1046324 , 0.10467429, 0.0999695 , 0.0910681 ,\n",
       "        0.1002737 , 0.09653253, 0.10596372, 0.10155382, 0.09745807],\n",
       "       [0.09782621, 0.10487468, 0.10494817, 0.10012546, 0.09086368,\n",
       "        0.10017112, 0.09635952, 0.10620799, 0.10111151, 0.09751166],\n",
       "       [0.09776573, 0.10473268, 0.10481993, 0.10003232, 0.09081399,\n",
       "        0.10017893, 0.09668631, 0.10619488, 0.10122969, 0.09754553],\n",
       "       [0.09769006, 0.10482336, 0.10439344, 0.10000278, 0.09092441,\n",
       "        0.10065881, 0.09657767, 0.10629877, 0.10174029, 0.0968904 ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(100,784)\n",
    "y = net.predict(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d94d8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-2b86bf493e4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# update params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-bafb495735d9>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\바탕 화면\\서울대(대학원)\\2022-1\\007.스터디\\밑바닥부터 시작하는 딥러닝1\\common\\gradient.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[1;34m(f, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mfxh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# f(x-h)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-bafb495735d9>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(W)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mloss_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-bafb495735d9>\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# t: 정답 레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-bafb495735d9>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\바탕 화면\\서울대(대학원)\\2022-1\\007.스터디\\밑바닥부터 시작하는 딥러닝1\\common\\functions.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 미니배치 학습 구현\n",
    "\n",
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "# 위의 TwoLayerNet 클래스 사용\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list=[]\n",
    "\n",
    "# hyperparameters\n",
    "iters_num = 10000     # 미니배치로 학습시키는 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100      # 60000개 데이터에서 임의로 100개씩 뽑아서\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 한 번에 minibatch 만큼 뽑아서 학습 -> 10000번\n",
    "for i in range(iters_num):\n",
    "    # get minibatch\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # gradient\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    # update params\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20e96908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.2942045397766893,\n",
       " 2.2985827060838147,\n",
       " 2.298191802442777,\n",
       " 2.2883365756330356,\n",
       " 2.2831202722733295,\n",
       " 2.289759391150756,\n",
       " 2.296208972236112,\n",
       " 2.2817541953040767,\n",
       " 2.291333328939462,\n",
       " 2.294243511105076,\n",
       " 2.309259547315103,\n",
       " 2.2892277571226374,\n",
       " 2.2942905496999866,\n",
       " 2.2860751060624147,\n",
       " 2.2973922642377858]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f26628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc | 0.09751666666666667, 0.0974\n"
     ]
    }
   ],
   "source": [
    "# 시험데이터 평가 추가\n",
    "\n",
    "# 미니배치 학습 구현\n",
    "\n",
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "# 위의 TwoLayerNet 클래스 사용\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list=[]\n",
    "train_acc_list=[]\n",
    "test_acc_list=[]\n",
    "\n",
    "# hyperparameters\n",
    "iters_num = 10000     # 미니배치로 학습시키는 횟수\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100      # 60000개 데이터에서 임의로 100개씩 뽑아서\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "# 1 epoch당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1) \n",
    "\n",
    "# 한 번에 minibatch 만큼 뽑아서 학습 -> 10000번\n",
    "for i in range(iters_num):\n",
    "    # get minibatch\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # gradient\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    # update params\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1 epoch 당 정확도 계산\n",
    "    if i%iter_per_epoch == 0 :\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \"+ str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71156cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "# 0~20까지 0.1 간격 배열의 x\n",
    "x = np.arange(0, 16)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(x, train_acc_list)\n",
    "plt.plot(x, test_acc_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90360682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
