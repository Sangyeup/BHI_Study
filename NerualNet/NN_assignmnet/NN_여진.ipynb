{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sangyeup/BHI_Study/blob/main/NN_%EC%97%AC%EC%A7%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97571e35",
      "metadata": {
        "id": "97571e35"
      },
      "source": [
        "# Build 3 Layer Network"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c6f07ec",
      "metadata": {
        "id": "8c6f07ec"
      },
      "source": [
        "- input layer\n",
        "- 2 hidden layer\n",
        "- output layer\n",
        "<br>\n",
        "<br>\n",
        "- Loss function : Cross Entropy Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5e4140c0",
      "metadata": {
        "id": "5e4140c0"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2mrWu4XZ7xE",
        "outputId": "07573b7e-ef15-4410-c015-a7e735b4ea41"
      },
      "id": "Q2mrWu4XZ7xE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 826, done.\u001b[K\n",
            "remote: Total 826 (delta 0), reused 0 (delta 0), pack-reused 826\u001b[K\n",
            "Receiving objects: 100% (826/826), 52.21 MiB | 27.25 MiB/s, done.\n",
            "Resolving deltas: 100% (477/477), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/deep-learning-from-scratch')\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUNUio1iZ8a7",
        "outputId": "4346de8c-8891-45f1-a70b-a3a79287e073"
      },
      "id": "ZUNUio1iZ8a7",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-from-scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18bddbfd",
      "metadata": {
        "id": "18bddbfd"
      },
      "source": [
        "## Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0cbc4f30",
      "metadata": {
        "id": "0cbc4f30"
      },
      "outputs": [],
      "source": [
        "# sigmoid\n",
        "\n",
        "def sigmoid(x):   \n",
        "    return 1/(1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bca860c0",
      "metadata": {
        "id": "bca860c0"
      },
      "outputs": [],
      "source": [
        "# cross_entropy_error\n",
        "# y : predicted value\n",
        "# t : label\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "  # print(y.shape)\n",
        "  # print(t.shape)\n",
        "  if y.ndim==1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "  delta = 1e-7\n",
        "  batch_size = y.shape[0]\n",
        "  loss = -np.sum(t*np.log(y+delta))/batch_size\n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "50dbc9d3",
      "metadata": {
        "id": "50dbc9d3"
      },
      "outputs": [],
      "source": [
        "# softmax\n",
        "# x : input\n",
        "# Overflow 방지 -> input 중 가장 큰 값 전체 데이터에서 빼주기\n",
        "\n",
        "def softmax(x):\n",
        "    c = x.max(axis=1, keepdims=True)\n",
        "    exp_a = np.exp(x-c)\n",
        "    sum_exp_a = exp_a.sum(axis=1, keepdims=True)\n",
        "    y = exp_a/sum_exp_a\n",
        "    return y\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e9c8f9bd",
      "metadata": {
        "id": "e9c8f9bd"
      },
      "outputs": [],
      "source": [
        "# numerical_gradient\n",
        "# 수치 미분법\n",
        "# f : function\n",
        "# x : variable\n",
        "# 각 변수에 대한 편미분 저장된 배열 return\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "  h = 1e-4\n",
        "  grad = np.zeros_like(x)\n",
        "  iter = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
        "  with iter:\n",
        "    while not iter.finished:\n",
        "      idx = iter.multi_index\n",
        "      temp_val = x[idx]\n",
        "      x[idx] = temp_val+h\n",
        "      fxh1 = f(x)\n",
        "      x[idx] = temp_val-h\n",
        "      fxh2 = f(x)\n",
        "      grad[idx] = (fxh1-fxh2)/(2*h)\n",
        "      x[idx] = temp_val\n",
        "      iter.iternext()\n",
        "\n",
        "  return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd1c9d0c",
      "metadata": {
        "id": "bd1c9d0c"
      },
      "source": [
        "## Define Network by Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "aad56126",
      "metadata": {
        "id": "aad56126"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerNet:\n",
        "    # 초기화\n",
        "    def __init__(self, input_size, hidden_size_1, hidden_size_2, output_size, weight_init_std=0.01):\n",
        "        \n",
        "        # initialize parameters\n",
        "        # W -> random \n",
        "        # b -> 0\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size_1)\n",
        "        self.params['b1'] = np.zeros(hidden_size_1)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size_1, hidden_size_2)\n",
        "        self.params['b2'] = np.zeros(hidden_size_2)\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size_2, output_size)\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "\n",
        "        \n",
        "        \n",
        "    # 예측 함수\n",
        "    # x : 입력 데이터\n",
        "    # y : 예측값\n",
        "    def predict(self,x):\n",
        "        W1, W2, W3 = self.params['W1'], self.params['W2'], self.params['W3']\n",
        "        b1, b2, b3 = self.params['b1'], self.params['b2'], self.params['b3']\n",
        "        a1 = np.dot(x, W1)+b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2)+b2\n",
        "        z2 = sigmoid(a2)\n",
        "        a3 = np.dot(z2, W3)+b3\n",
        "        y = softmax(a3)\n",
        "        return y\n",
        "    \n",
        "    \n",
        "    # 손실 함수\n",
        "    # cross_entropy_error 사용\n",
        "    # x : 입력 데이터\n",
        "    # t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        \n",
        "        y=self.predict(x)\n",
        "        return cross_entropy_error(y,t)\n",
        "    \n",
        "    \n",
        "    # 정확도 함수\n",
        "    # x : 입력 데이터\n",
        "    # t : 정답 레이블\n",
        "    # x 중 예측값 == 정답 레이블 비율\n",
        "    # accuracy = (정답 맞춘 데이터 수) / (전체 데이터 수)\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        t = np.argmax(t, axis=1)\n",
        "        accuracy = np.sum(y==t)/float(x.shape[0])\n",
        "        return accuracy\n",
        "    \n",
        "    \n",
        "    # 기울기 함수\n",
        "    # 수치 미분법으로 계산\n",
        "    # x : 입력 데이터\n",
        "    # t : 정답 레이블\n",
        "    def gradient(self, x, t):\n",
        "        # get loss function\n",
        "        loss_W = lambda W: self.loss(x,t)\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        grads['W3'] = numerical_gradient(loss_W, self.params['W3'])\n",
        "        grads['b3'] = numerical_gradient(loss_W, self.params['b3'])\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba400582",
      "metadata": {
        "id": "ba400582"
      },
      "source": [
        "## train, test - MNIST\n",
        "\n",
        "교재 github에서 /dataset/mnist.py 다운로드 후 load_mnist import해서 사용\n",
        "\n",
        "**ThreeLayerNet으로 train, test**\n",
        "\n",
        "- input_size = 784\n",
        "- hidden_size_1 = 50\n",
        "- hidden_size_2 = 100\n",
        "- output_size = 10\n",
        "- batch_size = 100\n",
        "- learning_rate = 0.1\n",
        "- iters_num = 5000\n",
        "- train_size = x_train data 전체\n",
        "\n",
        "**train loss 그래프 그리기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e4331635",
      "metadata": {
        "id": "e4331635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "6a0d5c3f-2afe-4050-cad3-de24001c8e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.11236666666666667 & Test Accuracy: 0.1135\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8359b1ef2a8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b36e105eb745>\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-7d1b5945367c>\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mtemp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_val\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mfxh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_val\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b36e105eb745>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# get loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mloss_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b36e105eb745>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-b36e105eb745>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys, os\n",
        "sys.path.append(os.pardir)\n",
        "\n",
        "from dataset.mnist import load_mnist\n",
        "\n",
        "# load dataset\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# Hyperparameters\n",
        "#### 채워 넣으세요 ####\n",
        "iters_num = 5000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = ThreeLayerNet(input_size=784, hidden_size_1=50, hidden_size_2=100, output_size=10)\n",
        "\n",
        "# 1 epoch 되는 iteration\n",
        "iter_per_epoch = max(train_size/batch_size, 1)\n",
        "\n",
        "# Train\n",
        "for i in range(iters_num):\n",
        "    # get minibatch\n",
        "    x_batch = x_train[i%train_size:i%train_size+batch_size]\n",
        "    t_batch = t_train[i%train_size:i%train_size+batch_size]\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "    for key in grad.keys():\n",
        "      network.params[key] -= learning_rate*grad[key]\n",
        "    # gradient 계산 후 parameter update 필요\n",
        "    \n",
        "    \n",
        "    # 학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "    \n",
        "    \n",
        "    # 1 epoch 당 accuracy 계산\n",
        "    if i%iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        \n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        \n",
        "        \n",
        "        print(\"Train Accuracy: \" + str(train_acc) + \" & \" + \"Test Accuracy: \" + str(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6995fefa",
      "metadata": {
        "id": "6995fefa"
      },
      "source": [
        "### Visualize Loss\n",
        "- loss 보여주는 plot\n",
        "\n",
        "- 맘대로 시각화하면 됩니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a980e19f",
      "metadata": {
        "id": "a980e19f"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "7b94ebc9",
      "metadata": {
        "id": "7b94ebc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "725f988e-2f2a-412f-cbce-57b7a80e771d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5a6cccfc028f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'trainacc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'best'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.plot(x, train_acc_list, label = 'train acc')\n",
        "plt.plot(x, test_acc_list, label = 'test acc', linestyle = '--')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb65473f",
      "metadata": {
        "id": "fb65473f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "NN_여진.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
