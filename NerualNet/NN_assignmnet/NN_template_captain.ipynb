{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97571e35",
   "metadata": {},
   "source": [
    "# Build 3 Layer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f07ec",
   "metadata": {},
   "source": [
    "- input layer\n",
    "- 2 hidden layer\n",
    "- output layer\n",
    "<br>\n",
    "<br>\n",
    "- Loss function : Cross Entropy Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4140c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bddbfd",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    return #### 채워 넣으세요 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca860c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy_error\n",
    "# y : predicted value\n",
    "# t : label\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    \n",
    "    #### 채워 넣으세요 ####\n",
    "    # log 진수에 0 들어가지 않도록 delta 고려\n",
    "    delta = 1e-7\n",
    "    \n",
    "    return  #### 채워 넣으세요 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax\n",
    "# x : input\n",
    "# Overflow 방지 -> input 중 가장 큰 값 전체 데이터에서 빼주기\n",
    "\n",
    "def softmax(x):\n",
    "    \n",
    "    #### 채워 넣으세요 ####\n",
    "    c = np.max(x)\n",
    "    \n",
    "    return  #### 채워 넣으세요 ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical_gradient\n",
    "# 수치 미분법\n",
    "# f : function\n",
    "# x : variable\n",
    "# 각 변수에 대한 편미분 저장된 배열 return\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    \n",
    "    #### 채워 넣으세요 ####\n",
    "    # iteration for each values\n",
    "    for idx in range(x.shape[0]):\n",
    "        tmp_val = x[idx]\n",
    "    \n",
    "        # f(x+h)\n",
    "    \n",
    "        # f(x-h)\n",
    "        \n",
    "        \n",
    "        grad[idx] = \n",
    "        x[idx] = tmp_val    # reset\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c9d0c",
   "metadata": {},
   "source": [
    "## Define Network by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad56126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerNet:\n",
    "    # 초기화\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, output_size, weight_init_std=0.01):\n",
    "        \n",
    "        # initialize parameters\n",
    "        # W -> random \n",
    "        # b -> 0\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size_1)\n",
    "        self.params['b1'] = np.zeros(hidden_size_1)\n",
    "        \n",
    "        #### 채워 넣으세요 ####\n",
    "        \n",
    "        \n",
    "    # 예측 함수\n",
    "    # x : 입력 데이터\n",
    "    # y : 예측값\n",
    "    def predict(self,x):\n",
    "        \n",
    "        #### 채워 넣으세요 ####\n",
    "        # activation function : output 이전은 sigmoid\n",
    "        \n",
    "        \n",
    "        y = softmax(a3)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    # 손실 함수\n",
    "    # cross_entropy_error 사용\n",
    "    # x : 입력 데이터\n",
    "    # t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        \n",
    "        #### 채워 넣으세요 ####\n",
    "        \n",
    "        return  #### 채워 넣으세요 ####\n",
    "    \n",
    "    \n",
    "    # 정확도 함수\n",
    "    # x : 입력 데이터\n",
    "    # t : 정답 레이블\n",
    "    # x 중 예측값 == 정답 레이블 비율\n",
    "    # accuracy = (정답 맞춘 데이터 수) / (전체 데이터 수)\n",
    "    def accuracy(self, x, t):\n",
    "        \n",
    "        #### 채워 넣으세요 ####\n",
    "        \n",
    "        return  #### 채워 넣으세요 ####\n",
    "    \n",
    "    \n",
    "    # 기울기 함수\n",
    "    # 수치 미분법으로 계산\n",
    "    # x : 입력 데이터\n",
    "    # t : 정답 레이블\n",
    "    def gradient(self, x, t):\n",
    "        # get loss function\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] =  #### 채워 넣으세요 ####\n",
    "        \n",
    "        #### 채워 넣으세요 ####\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba400582",
   "metadata": {},
   "source": [
    "## train, test - MNIST\n",
    "\n",
    "교재 github에서 /dataset/mnist.py 다운로드 후 load_mnist import해서 사용\n",
    "\n",
    "**ThreeLayerNet으로 train, test**\n",
    "\n",
    "- input_size = 784\n",
    "- hidden_size_1 = 50\n",
    "- hidden_size_2 = 100\n",
    "- output_size = 10\n",
    "- batch_size = 100\n",
    "- learning_rate = 0.1\n",
    "- iters_num = 5000\n",
    "- train_size = x_train data 전체\n",
    "\n",
    "**train loss 그래프 그리기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4331635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# load dataset\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# Hyperparameters\n",
    "#### 채워 넣으세요 ####\n",
    "iters_num = \n",
    "train_size = x_train.shape[0]\n",
    "batch_size = \n",
    "learning_rate = \n",
    "\n",
    "network = ThreeLayerNet(#### 채워 넣으세요 ####)\n",
    "\n",
    "# 1 epoch 되는 iteration\n",
    "iter_per_epoch = max(train_size/batch_size, 1)\n",
    "\n",
    "# Train\n",
    "for i in range(iters_num):\n",
    "    # get minibatch\n",
    "    # not random\n",
    "    x_batch = x_train[i%train_size:i%train_size+batch_size]\n",
    "    t_batch = t_train[i%train_size:i%train_size+batch_size]\n",
    "    \n",
    "    #### 채워 넣으세요 ####\n",
    "    # gradient 계산 후 parameter update 필요\n",
    "    \n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    \n",
    "    # 1 epoch 당 accuracy 계산\n",
    "    if i%iter_per_epoch == 0:\n",
    "        #### 채워 넣으세요 ####\n",
    "        # train accuracy, test accuracy 각각 계산 후 (모델에서 정의한 accuracy 함수 이용)\n",
    "        # train_acc_list, test_acc_list에 각각 accuracy append\n",
    "        train_acc = \n",
    "        test_acc = \n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "        \n",
    "        print(\"Train Accuracy: \" + str(train_acc) + \" & \" + \"Test Accuracy: \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995fefa",
   "metadata": {},
   "source": [
    "### Visualize Loss\n",
    "- loss 보여주는 plot\n",
    "\n",
    "- 맘대로 시각화하면 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980e19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94ebc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb65473f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
